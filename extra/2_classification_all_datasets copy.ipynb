{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Pipeline Summary\n",
    "\n",
    "## 1. Datasets and Models Used\n",
    "   - **Datasets**:\n",
    "     - 4 datasets in total: three individual datasets and one combined dataset.\n",
    "   - **Models**:\n",
    "     - VGG16.\n",
    "     - ResNet50.\n",
    "     - EfficientNetB0.\n",
    "     - InceptionV3.\n",
    "\n",
    "## 2. Experiment Setup\n",
    "   - **Hyperparameter Ranges**:\n",
    "     - **Batch Size**: [16, 32, 64, 128].\n",
    "     - **Learning Rate**: [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005].\n",
    "     - **Epochs**: [15, 25, 35, 50].\n",
    "   - Selected optimal hyperparameters for each model based on validation performance.\n",
    "\n",
    "## 3. Training and Validation Process\n",
    "   - **Training Loop**:\n",
    "     - Optimized models over multiple epochs.\n",
    "     - Logged training and validation accuracy and loss per epoch.\n",
    "     - Tracked total training time for each model.\n",
    "   - **Validation**:\n",
    "     - Monitored model performance with validation data to track generalization and prevent overfitting.\n",
    "\n",
    "## 4. Evaluation Metrics and Visualizations\n",
    "   - **Test Set Evaluation**:\n",
    "     - Assessed model performance using the macro-averaged F1 score.\n",
    "     - Generated precision, recall, and F1 scores for each class.\n",
    "   - **Visualizations**:\n",
    "     - Confusion Matrix for class-wise prediction analysis.\n",
    "     - Classification Report Heatmap with precision, recall, and F1 scores.\n",
    "     - ROC Curves for multi-class AUC (Area Under the Curve) evaluation.\n",
    "\n",
    "## 5. Key Outputs for Each Dataset-Model Combination\n",
    "   - **Training and Validation Curves**:\n",
    "     - Generated and saved plots for training and validation accuracy and loss for each model-dataset pairing.\n",
    "   - **Model State Saving**:\n",
    "     - Saved trained model states for potential future use.\n",
    "   - **Detailed Metrics Visualization**:\n",
    "     - Produced visualizations including classification reports, confusion matrices, and ROC curves for comprehensive performance analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Virtual Environment</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /scratch/movi/dmp/lib/python3.9/site-packages (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (1.8.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (8.18.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (24.1)\n",
      "Requirement already satisfied: psutil in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in /scratch/movi/dmp/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /scratch/movi/dmp/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in /scratch/movi/dmp/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup in /scratch/movi/dmp/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /scratch/movi/dmp/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /scratch/movi/dmp/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (8.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /scratch/movi/dmp/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /scratch/movi/dmp/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
      "Requirement already satisfied: zipp>=3.20 in /scratch/movi/dmp/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.20.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /scratch/movi/dmp/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /scratch/movi/dmp/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /scratch/movi/dmp/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /scratch/movi/dmp/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /scratch/movi/dmp/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /scratch/movi/dmp/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /scratch/movi/dmp/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Installed kernelspec dmp in /home/movi/.local/share/jupyter/kernels/dmp\n"
     ]
    }
   ],
   "source": [
    "# # Create the virtual environment named 'dmp'\n",
    "!python3 -m venv /scratch/movi/dmp\n",
    "# Install ipykernel inside the 'dmp' environment\n",
    "!/scratch/movi/dmp/bin/pip install ipykernel\n",
    "# Add 'dmp' as a kernel for Jupyter Notebook\n",
    "!/scratch/movi/dmp/bin/python -m ipykernel install --user --name=dmp --display-name \"Python (dmp)\"\n",
    "# # Upgrade pip in the 'dmp' environment\n",
    "# !/scratch/movi/dmp/bin/python3 -m pip install --upgrade pip\n",
    "# # Install necessary packages (NumPy, PyTorch, etc.) inside 'dmp'\n",
    "# !/scratch/movi/dmp/bin/pip install numpy torch torchvision torchaudio pandas matplotlib scikit-learn\n",
    "# !pip install numpy==1.21.4 scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.9.9 (main, Mar 25 2022, 16:08:31) \n",
      "[GCC 10.3.0]\n",
      "NumPy Version: 1.21.4\n",
      "PyTorch Version: 1.12.1+cu113\n",
      "CUDA is available. PyTorch is using GPU.\n",
      "\n",
      "Number of GPUs available: 1\n",
      "\n",
      "GPU 0: NVIDIA A100-SXM4-80GB MIG 3g.40gb\n",
      "  Total Memory: 39.25 GB\n",
      "  Memory Allocated: 0.00 GB\n",
      "  Memory Reserved (Cached): 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# Prints the installed versions of Python, NumPy, and PyTorch libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"NumPy Version: {np.__version__}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Function to check GPU availability and display memory statistics using PyTorch's CUDA interface\n",
    "def check_gpu_status():\n",
    "    # Check if GPU is available\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA is available. PyTorch is using GPU.\\n\")\n",
    "        # Get the number of available GPUs\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(f\"Number of GPUs available: {num_gpus}\")\n",
    "        # Loop through each GPU and display its details\n",
    "        for gpu_id in range(num_gpus):\n",
    "            gpu_name = torch.cuda.get_device_name(gpu_id)\n",
    "            gpu_memory_allocated = torch.cuda.memory_allocated(gpu_id) / (1024 ** 3)  # In GB\n",
    "            gpu_memory_cached = torch.cuda.memory_reserved(gpu_id) / (1024 ** 3)      # In GB\n",
    "            gpu_memory_total = torch.cuda.get_device_properties(gpu_id).total_memory / (1024 ** 3)  # In GB\n",
    "            print(f\"\\nGPU {gpu_id}: {gpu_name}\")\n",
    "            print(f\"  Total Memory: {gpu_memory_total:.2f} GB\")\n",
    "            print(f\"  Memory Allocated: {gpu_memory_allocated:.2f} GB\")\n",
    "            print(f\"  Memory Reserved (Cached): {gpu_memory_cached:.2f} GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. PyTorch is using the CPU.\")\n",
    "\n",
    "# Run the GPU status check\n",
    "check_gpu_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Dataset 01</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">VGG16 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 07:47:38,118 - Training dataset size: 10021\n",
      "2024-11-12 07:47:38,118 - Validation dataset size: 1199\n",
      "2024-11-12 07:47:38,119 - Test dataset size: 1342\n",
      "2024-11-12 07:47:38,120 - Training with Batch Size: 128, Learning Rate: 5e-05, Epochs: 25\n",
      "2024-11-12 07:48:35,074 - Epoch 1/25 - Training: Loss = 1.9407, Accuracy = 0.2608\n",
      "2024-11-12 07:48:37,918 - Epoch 1/25 - Validation: Loss = 1.6878, Accuracy = 0.3878\n",
      "2024-11-12 07:48:37,919 - Time for epoch 1: 57.29s\n",
      "2024-11-12 07:49:26,708 - Epoch 2/25 - Training: Loss = 1.5408, Accuracy = 0.4465\n",
      "2024-11-12 07:49:29,262 - Epoch 2/25 - Validation: Loss = 1.4193, Accuracy = 0.5263\n",
      "2024-11-12 07:49:29,263 - Time for epoch 2: 51.34s\n",
      "2024-11-12 07:50:21,012 - Epoch 3/25 - Training: Loss = 1.2478, Accuracy = 0.5667\n",
      "2024-11-12 07:50:25,240 - Epoch 3/25 - Validation: Loss = 1.1846, Accuracy = 0.5796\n",
      "2024-11-12 07:50:25,241 - Time for epoch 3: 55.98s\n",
      "2024-11-12 07:51:14,560 - Epoch 4/25 - Training: Loss = 0.9671, Accuracy = 0.6613\n",
      "2024-11-12 07:51:26,655 - Epoch 4/25 - Validation: Loss = 0.9133, Accuracy = 0.7039\n",
      "2024-11-12 07:51:26,657 - Time for epoch 4: 61.41s\n",
      "2024-11-12 07:52:15,970 - Epoch 5/25 - Training: Loss = 0.7213, Accuracy = 0.7510\n",
      "2024-11-12 07:52:18,989 - Epoch 5/25 - Validation: Loss = 0.7477, Accuracy = 0.7456\n",
      "2024-11-12 07:52:18,990 - Time for epoch 5: 52.33s\n",
      "2024-11-12 07:53:21,351 - Epoch 6/25 - Training: Loss = 0.5590, Accuracy = 0.8111\n",
      "2024-11-12 07:53:23,979 - Epoch 6/25 - Validation: Loss = 0.6900, Accuracy = 0.7948\n",
      "2024-11-12 07:53:23,980 - Time for epoch 6: 64.99s\n",
      "2024-11-12 07:54:13,554 - Epoch 7/25 - Training: Loss = 0.4395, Accuracy = 0.8529\n",
      "2024-11-12 07:54:16,131 - Epoch 7/25 - Validation: Loss = 0.4503, Accuracy = 0.8457\n",
      "2024-11-12 07:54:16,132 - Time for epoch 7: 52.15s\n",
      "2024-11-12 07:55:05,741 - Epoch 8/25 - Training: Loss = 0.2855, Accuracy = 0.9025\n",
      "2024-11-12 07:55:08,467 - Epoch 8/25 - Validation: Loss = 0.3248, Accuracy = 0.8974\n",
      "2024-11-12 07:55:08,467 - Time for epoch 8: 52.33s\n",
      "2024-11-12 07:55:57,639 - Epoch 9/25 - Training: Loss = 0.2001, Accuracy = 0.9330\n",
      "2024-11-12 07:56:00,852 - Epoch 9/25 - Validation: Loss = 0.3406, Accuracy = 0.8966\n",
      "2024-11-12 07:56:00,853 - Time for epoch 9: 52.38s\n",
      "2024-11-12 07:56:54,309 - Epoch 10/25 - Training: Loss = 0.1690, Accuracy = 0.9437\n",
      "2024-11-12 07:56:57,872 - Epoch 10/25 - Validation: Loss = 0.2392, Accuracy = 0.9274\n",
      "2024-11-12 07:56:57,873 - Time for epoch 10: 57.02s\n",
      "2024-11-12 07:57:46,727 - Epoch 11/25 - Training: Loss = 0.1258, Accuracy = 0.9582\n",
      "2024-11-12 07:57:49,363 - Epoch 11/25 - Validation: Loss = 0.1762, Accuracy = 0.9408\n",
      "2024-11-12 07:57:49,364 - Time for epoch 11: 51.49s\n",
      "2024-11-12 07:58:43,923 - Epoch 12/25 - Training: Loss = 0.0801, Accuracy = 0.9732\n",
      "2024-11-12 07:58:53,537 - Epoch 12/25 - Validation: Loss = 0.1644, Accuracy = 0.9525\n",
      "2024-11-12 07:58:53,539 - Time for epoch 12: 64.17s\n",
      "2024-11-12 07:59:54,033 - Epoch 13/25 - Training: Loss = 0.0678, Accuracy = 0.9789\n",
      "2024-11-12 07:59:56,962 - Epoch 13/25 - Validation: Loss = 0.1602, Accuracy = 0.9450\n",
      "2024-11-12 07:59:56,963 - Time for epoch 13: 63.42s\n",
      "2024-11-12 08:00:52,480 - Epoch 14/25 - Training: Loss = 0.0596, Accuracy = 0.9798\n",
      "2024-11-12 08:00:56,364 - Epoch 14/25 - Validation: Loss = 0.1707, Accuracy = 0.9450\n",
      "2024-11-12 08:00:56,365 - Time for epoch 14: 59.40s\n",
      "2024-11-12 08:01:46,452 - Epoch 15/25 - Training: Loss = 0.0483, Accuracy = 0.9838\n",
      "2024-11-12 08:01:52,561 - Epoch 15/25 - Validation: Loss = 0.1968, Accuracy = 0.9491\n",
      "2024-11-12 08:01:52,563 - Time for epoch 15: 56.20s\n",
      "2024-11-12 08:02:58,307 - Epoch 16/25 - Training: Loss = 0.0554, Accuracy = 0.9824\n",
      "2024-11-12 08:03:01,007 - Epoch 16/25 - Validation: Loss = 0.2914, Accuracy = 0.9208\n",
      "2024-11-12 08:03:01,008 - Time for epoch 16: 68.44s\n",
      "2024-11-12 08:03:51,875 - Epoch 17/25 - Training: Loss = 0.0417, Accuracy = 0.9866\n",
      "2024-11-12 08:03:54,543 - Epoch 17/25 - Validation: Loss = 0.1943, Accuracy = 0.9500\n",
      "2024-11-12 08:03:54,544 - Time for epoch 17: 53.53s\n",
      "2024-11-12 08:04:44,419 - Epoch 18/25 - Training: Loss = 0.0292, Accuracy = 0.9905\n",
      "2024-11-12 08:04:47,046 - Epoch 18/25 - Validation: Loss = 0.1308, Accuracy = 0.9583\n",
      "2024-11-12 08:04:47,046 - Time for epoch 18: 52.50s\n",
      "2024-11-12 08:05:38,617 - Epoch 19/25 - Training: Loss = 0.0305, Accuracy = 0.9898\n",
      "2024-11-12 08:05:42,223 - Epoch 19/25 - Validation: Loss = 0.1835, Accuracy = 0.9475\n",
      "2024-11-12 08:05:42,224 - Time for epoch 19: 55.18s\n",
      "2024-11-12 08:06:31,230 - Epoch 20/25 - Training: Loss = 0.0324, Accuracy = 0.9893\n",
      "2024-11-12 08:06:36,189 - Epoch 20/25 - Validation: Loss = 0.2837, Accuracy = 0.9383\n",
      "2024-11-12 08:06:36,190 - Time for epoch 20: 53.96s\n",
      "2024-11-12 08:07:27,073 - Epoch 21/25 - Training: Loss = 0.0249, Accuracy = 0.9917\n",
      "2024-11-12 08:07:30,027 - Epoch 21/25 - Validation: Loss = 0.1967, Accuracy = 0.9525\n",
      "2024-11-12 08:07:30,028 - Time for epoch 21: 53.84s\n",
      "2024-11-12 08:08:19,343 - Epoch 22/25 - Training: Loss = 0.0265, Accuracy = 0.9923\n",
      "2024-11-12 08:08:21,952 - Epoch 22/25 - Validation: Loss = 0.3214, Accuracy = 0.9333\n",
      "2024-11-12 08:08:21,953 - Time for epoch 22: 51.92s\n",
      "2024-11-12 08:09:14,283 - Epoch 23/25 - Training: Loss = 0.0273, Accuracy = 0.9915\n",
      "2024-11-12 08:09:20,049 - Epoch 23/25 - Validation: Loss = 0.1334, Accuracy = 0.9633\n",
      "2024-11-12 08:09:20,050 - Time for epoch 23: 58.10s\n",
      "2024-11-12 08:10:08,841 - Epoch 24/25 - Training: Loss = 0.0181, Accuracy = 0.9946\n",
      "2024-11-12 08:10:12,797 - Epoch 24/25 - Validation: Loss = 0.1640, Accuracy = 0.9575\n",
      "2024-11-12 08:10:12,798 - Time for epoch 24: 52.75s\n",
      "2024-11-12 08:11:02,154 - Epoch 25/25 - Training: Loss = 0.0239, Accuracy = 0.9931\n",
      "2024-11-12 08:11:04,767 - Epoch 25/25 - Validation: Loss = 0.2807, Accuracy = 0.9349\n",
      "2024-11-12 08:11:04,767 - Time for epoch 25: 51.97s\n",
      "2024-11-12 08:11:04,768 - Total Training Time: 1404.11s\n",
      "2024-11-12 08:11:10,057 - Macro-Averaged F1 Score: 0.9425\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using VGG16\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.00005]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 9\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.vgg16(weights=None)\n",
    "            model.classifier[6] = nn.Linear(model.classifier[6].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 01 VGG16 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_01_vgg16_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 01 VGG16 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_01_vgg16_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 01 VGG16 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_01_vgg16_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 01 VGG16 Confusion Matrix\")\n",
    "                plt.savefig('dataset_01_vgg16_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 01 VGG16 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_01_vgg16_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_01_vgg16_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">ResNet50 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 08:11:12,961 - Training dataset size: 10021\n",
      "2024-11-12 08:11:12,962 - Validation dataset size: 1199\n",
      "2024-11-12 08:11:12,962 - Test dataset size: 1342\n",
      "2024-11-12 08:11:12,963 - Training with Batch Size: 64, Learning Rate: 5e-05, Epochs: 25\n",
      "2024-11-12 08:11:48,688 - Epoch 1/25 - Training: Loss = 1.8871, Accuracy = 0.2992\n",
      "2024-11-12 08:11:50,827 - Epoch 1/25 - Validation: Loss = 1.6812, Accuracy = 0.3686\n",
      "2024-11-12 08:11:50,828 - Time for epoch 1: 37.65s\n",
      "2024-11-12 08:12:29,718 - Epoch 2/25 - Training: Loss = 1.5856, Accuracy = 0.4060\n",
      "2024-11-12 08:12:31,811 - Epoch 2/25 - Validation: Loss = 1.6096, Accuracy = 0.3778\n",
      "2024-11-12 08:12:31,812 - Time for epoch 2: 40.98s\n",
      "2024-11-12 08:13:05,787 - Epoch 3/25 - Training: Loss = 1.4617, Accuracy = 0.4604\n",
      "2024-11-12 08:13:07,830 - Epoch 3/25 - Validation: Loss = 1.4555, Accuracy = 0.4662\n",
      "2024-11-12 08:13:07,831 - Time for epoch 3: 36.02s\n",
      "2024-11-12 08:13:41,944 - Epoch 4/25 - Training: Loss = 1.3269, Accuracy = 0.5111\n",
      "2024-11-12 08:13:44,894 - Epoch 4/25 - Validation: Loss = 1.3999, Accuracy = 0.4929\n",
      "2024-11-12 08:13:44,895 - Time for epoch 4: 37.06s\n",
      "2024-11-12 08:14:19,571 - Epoch 5/25 - Training: Loss = 1.1619, Accuracy = 0.5795\n",
      "2024-11-12 08:14:21,641 - Epoch 5/25 - Validation: Loss = 1.2288, Accuracy = 0.5788\n",
      "2024-11-12 08:14:21,642 - Time for epoch 5: 36.75s\n",
      "2024-11-12 08:14:54,349 - Epoch 6/25 - Training: Loss = 1.0031, Accuracy = 0.6403\n",
      "2024-11-12 08:14:56,919 - Epoch 6/25 - Validation: Loss = 1.0659, Accuracy = 0.5988\n",
      "2024-11-12 08:14:56,920 - Time for epoch 6: 35.28s\n",
      "2024-11-12 08:15:29,775 - Epoch 7/25 - Training: Loss = 0.8493, Accuracy = 0.6983\n",
      "2024-11-12 08:15:32,026 - Epoch 7/25 - Validation: Loss = 1.0013, Accuracy = 0.6664\n",
      "2024-11-12 08:15:32,027 - Time for epoch 7: 35.11s\n",
      "2024-11-12 08:16:07,371 - Epoch 8/25 - Training: Loss = 0.7117, Accuracy = 0.7502\n",
      "2024-11-12 08:16:09,430 - Epoch 8/25 - Validation: Loss = 0.8668, Accuracy = 0.7014\n",
      "2024-11-12 08:16:09,431 - Time for epoch 8: 37.40s\n",
      "2024-11-12 08:16:43,167 - Epoch 9/25 - Training: Loss = 0.6027, Accuracy = 0.7886\n",
      "2024-11-12 08:16:45,320 - Epoch 9/25 - Validation: Loss = 0.6902, Accuracy = 0.7698\n",
      "2024-11-12 08:16:45,321 - Time for epoch 9: 35.89s\n",
      "2024-11-12 08:17:17,625 - Epoch 10/25 - Training: Loss = 0.4662, Accuracy = 0.8409\n",
      "2024-11-12 08:17:19,649 - Epoch 10/25 - Validation: Loss = 0.6510, Accuracy = 0.7740\n",
      "2024-11-12 08:17:19,650 - Time for epoch 10: 34.33s\n",
      "2024-11-12 08:17:54,216 - Epoch 11/25 - Training: Loss = 0.3688, Accuracy = 0.8786\n",
      "2024-11-12 08:17:56,211 - Epoch 11/25 - Validation: Loss = 0.5541, Accuracy = 0.8098\n",
      "2024-11-12 08:17:56,212 - Time for epoch 11: 36.56s\n",
      "2024-11-12 08:19:27,582 - Epoch 12/25 - Training: Loss = 0.2969, Accuracy = 0.9017\n",
      "2024-11-12 08:19:29,883 - Epoch 12/25 - Validation: Loss = 0.5234, Accuracy = 0.8224\n",
      "2024-11-12 08:19:29,885 - Time for epoch 12: 93.67s\n",
      "2024-11-12 08:20:04,453 - Epoch 13/25 - Training: Loss = 0.2237, Accuracy = 0.9291\n",
      "2024-11-12 08:20:06,458 - Epoch 13/25 - Validation: Loss = 0.4780, Accuracy = 0.8340\n",
      "2024-11-12 08:20:06,459 - Time for epoch 13: 36.57s\n",
      "2024-11-12 08:20:51,422 - Epoch 14/25 - Training: Loss = 0.1777, Accuracy = 0.9433\n",
      "2024-11-12 08:20:53,464 - Epoch 14/25 - Validation: Loss = 0.5013, Accuracy = 0.8299\n",
      "2024-11-12 08:20:53,465 - Time for epoch 14: 47.00s\n",
      "2024-11-12 08:21:27,254 - Epoch 15/25 - Training: Loss = 0.1411, Accuracy = 0.9571\n",
      "2024-11-12 08:21:29,386 - Epoch 15/25 - Validation: Loss = 0.4087, Accuracy = 0.8724\n",
      "2024-11-12 08:21:29,388 - Time for epoch 15: 35.92s\n",
      "2024-11-12 08:22:01,250 - Epoch 16/25 - Training: Loss = 0.1036, Accuracy = 0.9702\n",
      "2024-11-12 08:22:03,929 - Epoch 16/25 - Validation: Loss = 0.3416, Accuracy = 0.8816\n",
      "2024-11-12 08:22:03,930 - Time for epoch 16: 34.54s\n",
      "2024-11-12 08:22:41,648 - Epoch 17/25 - Training: Loss = 0.0827, Accuracy = 0.9764\n",
      "2024-11-12 08:22:44,090 - Epoch 17/25 - Validation: Loss = 0.3534, Accuracy = 0.8824\n",
      "2024-11-12 08:22:44,092 - Time for epoch 17: 40.16s\n",
      "2024-11-12 08:23:29,612 - Epoch 18/25 - Training: Loss = 0.0725, Accuracy = 0.9792\n",
      "2024-11-12 08:23:31,900 - Epoch 18/25 - Validation: Loss = 0.3525, Accuracy = 0.8816\n",
      "2024-11-12 08:23:31,901 - Time for epoch 18: 47.81s\n",
      "2024-11-12 08:24:06,085 - Epoch 19/25 - Training: Loss = 0.0618, Accuracy = 0.9811\n",
      "2024-11-12 08:24:08,089 - Epoch 19/25 - Validation: Loss = 0.2979, Accuracy = 0.9041\n",
      "2024-11-12 08:24:08,091 - Time for epoch 19: 36.19s\n",
      "2024-11-12 08:24:40,260 - Epoch 20/25 - Training: Loss = 0.0495, Accuracy = 0.9860\n",
      "2024-11-12 08:24:42,338 - Epoch 20/25 - Validation: Loss = 0.3149, Accuracy = 0.8966\n",
      "2024-11-12 08:24:42,339 - Time for epoch 20: 34.25s\n",
      "2024-11-12 08:25:17,506 - Epoch 21/25 - Training: Loss = 0.0606, Accuracy = 0.9814\n",
      "2024-11-12 08:25:19,509 - Epoch 21/25 - Validation: Loss = 0.3568, Accuracy = 0.8891\n",
      "2024-11-12 08:25:19,510 - Time for epoch 21: 37.17s\n",
      "2024-11-12 08:25:52,570 - Epoch 22/25 - Training: Loss = 0.0407, Accuracy = 0.9885\n",
      "2024-11-12 08:25:54,595 - Epoch 22/25 - Validation: Loss = 0.2720, Accuracy = 0.9166\n",
      "2024-11-12 08:25:54,596 - Time for epoch 22: 35.08s\n",
      "2024-11-12 08:26:42,862 - Epoch 23/25 - Training: Loss = 0.0321, Accuracy = 0.9911\n",
      "2024-11-12 08:26:45,540 - Epoch 23/25 - Validation: Loss = 0.3761, Accuracy = 0.8941\n",
      "2024-11-12 08:26:45,541 - Time for epoch 23: 50.94s\n",
      "2024-11-12 08:27:25,729 - Epoch 24/25 - Training: Loss = 0.0288, Accuracy = 0.9923\n",
      "2024-11-12 08:27:27,797 - Epoch 24/25 - Validation: Loss = 0.3613, Accuracy = 0.8916\n",
      "2024-11-12 08:27:27,797 - Time for epoch 24: 42.26s\n",
      "2024-11-12 08:28:04,701 - Epoch 25/25 - Training: Loss = 0.0468, Accuracy = 0.9850\n",
      "2024-11-12 08:28:06,744 - Epoch 25/25 - Validation: Loss = 0.3489, Accuracy = 0.8916\n",
      "2024-11-12 08:28:06,745 - Time for epoch 25: 38.95s\n",
      "2024-11-12 08:28:06,745 - Total Training Time: 1013.53s\n",
      "2024-11-12 08:28:09,872 - Macro-Averaged F1 Score: 0.9077\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using ResNet50\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.00005]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 9\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.resnet50(weights=None)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 01 ResNet50 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_01_resnet50_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 01 ResNet50 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_01_resnet50_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 01 ResNet50 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_01_resnet50_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 01 ResNet50 Confusion Matrix\")\n",
    "                plt.savefig('dataset_01_resnet50_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 01 ResNet50 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_01_resnet50_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_01_resnet50_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">EfficientNet_B0 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 08:28:12,062 - Training dataset size: 10021\n",
      "2024-11-12 08:28:12,063 - Validation dataset size: 1199\n",
      "2024-11-12 08:28:12,063 - Test dataset size: 1342\n",
      "2024-11-12 08:28:12,065 - Training with Batch Size: 64, Learning Rate: 5e-05, Epochs: 25\n",
      "2024-11-12 08:28:43,650 - Epoch 1/25 - Training: Loss = 2.1359, Accuracy = 0.1819\n",
      "2024-11-12 08:28:45,358 - Epoch 1/25 - Validation: Loss = 2.0013, Accuracy = 0.2294\n",
      "2024-11-12 08:28:45,359 - Time for epoch 1: 33.22s\n",
      "2024-11-12 08:29:15,362 - Epoch 2/25 - Training: Loss = 1.8916, Accuracy = 0.2976\n",
      "2024-11-12 08:29:17,058 - Epoch 2/25 - Validation: Loss = 1.8397, Accuracy = 0.2952\n",
      "2024-11-12 08:29:17,059 - Time for epoch 2: 31.70s\n",
      "2024-11-12 08:29:48,771 - Epoch 3/25 - Training: Loss = 1.7419, Accuracy = 0.3584\n",
      "2024-11-12 08:29:50,465 - Epoch 3/25 - Validation: Loss = 1.6756, Accuracy = 0.3461\n",
      "2024-11-12 08:29:50,466 - Time for epoch 3: 33.41s\n",
      "2024-11-12 08:30:20,538 - Epoch 4/25 - Training: Loss = 1.5934, Accuracy = 0.4182\n",
      "2024-11-12 08:30:22,243 - Epoch 4/25 - Validation: Loss = 1.4938, Accuracy = 0.4579\n",
      "2024-11-12 08:30:22,244 - Time for epoch 4: 31.78s\n",
      "2024-11-12 08:30:54,074 - Epoch 5/25 - Training: Loss = 1.4141, Accuracy = 0.4863\n",
      "2024-11-12 08:30:59,158 - Epoch 5/25 - Validation: Loss = 1.2822, Accuracy = 0.5071\n",
      "2024-11-12 08:30:59,159 - Time for epoch 5: 36.91s\n",
      "2024-11-12 08:31:34,712 - Epoch 6/25 - Training: Loss = 1.2329, Accuracy = 0.5633\n",
      "2024-11-12 08:31:36,426 - Epoch 6/25 - Validation: Loss = 1.1450, Accuracy = 0.5755\n",
      "2024-11-12 08:31:36,427 - Time for epoch 6: 37.27s\n",
      "2024-11-12 08:32:08,676 - Epoch 7/25 - Training: Loss = 1.0931, Accuracy = 0.6069\n",
      "2024-11-12 08:32:10,348 - Epoch 7/25 - Validation: Loss = 0.9771, Accuracy = 0.6414\n",
      "2024-11-12 08:32:10,349 - Time for epoch 7: 33.92s\n",
      "2024-11-12 08:33:08,241 - Epoch 8/25 - Training: Loss = 0.9606, Accuracy = 0.6539\n",
      "2024-11-12 08:33:09,939 - Epoch 8/25 - Validation: Loss = 0.8565, Accuracy = 0.6897\n",
      "2024-11-12 08:33:09,940 - Time for epoch 8: 59.59s\n",
      "2024-11-12 08:33:40,116 - Epoch 9/25 - Training: Loss = 0.8154, Accuracy = 0.7145\n",
      "2024-11-12 08:33:41,835 - Epoch 9/25 - Validation: Loss = 0.7805, Accuracy = 0.7323\n",
      "2024-11-12 08:33:41,836 - Time for epoch 9: 31.89s\n",
      "2024-11-12 08:34:11,643 - Epoch 10/25 - Training: Loss = 0.7142, Accuracy = 0.7443\n",
      "2024-11-12 08:34:13,359 - Epoch 10/25 - Validation: Loss = 0.6886, Accuracy = 0.7648\n",
      "2024-11-12 08:34:13,360 - Time for epoch 10: 31.52s\n",
      "2024-11-12 08:34:55,310 - Epoch 11/25 - Training: Loss = 0.6314, Accuracy = 0.7768\n",
      "2024-11-12 08:34:57,253 - Epoch 11/25 - Validation: Loss = 0.6625, Accuracy = 0.7673\n",
      "2024-11-12 08:34:57,254 - Time for epoch 11: 43.89s\n",
      "2024-11-12 08:35:27,307 - Epoch 12/25 - Training: Loss = 0.5572, Accuracy = 0.8102\n",
      "2024-11-12 08:35:29,038 - Epoch 12/25 - Validation: Loss = 0.5677, Accuracy = 0.8057\n",
      "2024-11-12 08:35:29,040 - Time for epoch 12: 31.78s\n",
      "2024-11-12 08:35:59,470 - Epoch 13/25 - Training: Loss = 0.4758, Accuracy = 0.8299\n",
      "2024-11-12 08:36:01,205 - Epoch 13/25 - Validation: Loss = 0.4899, Accuracy = 0.8340\n",
      "2024-11-12 08:36:01,206 - Time for epoch 13: 32.16s\n",
      "2024-11-12 08:36:31,137 - Epoch 14/25 - Training: Loss = 0.4076, Accuracy = 0.8592\n",
      "2024-11-12 08:36:32,966 - Epoch 14/25 - Validation: Loss = 0.5181, Accuracy = 0.8365\n",
      "2024-11-12 08:36:32,968 - Time for epoch 14: 31.76s\n",
      "2024-11-12 08:37:05,416 - Epoch 15/25 - Training: Loss = 0.3709, Accuracy = 0.8726\n",
      "2024-11-12 08:37:07,187 - Epoch 15/25 - Validation: Loss = 0.4469, Accuracy = 0.8507\n",
      "2024-11-12 08:37:07,189 - Time for epoch 15: 34.22s\n",
      "2024-11-12 08:37:39,195 - Epoch 16/25 - Training: Loss = 0.3228, Accuracy = 0.8913\n",
      "2024-11-12 08:37:40,979 - Epoch 16/25 - Validation: Loss = 0.4357, Accuracy = 0.8565\n",
      "2024-11-12 08:37:40,980 - Time for epoch 16: 33.79s\n",
      "2024-11-12 08:38:11,812 - Epoch 17/25 - Training: Loss = 0.3047, Accuracy = 0.8978\n",
      "2024-11-12 08:38:13,523 - Epoch 17/25 - Validation: Loss = 0.3591, Accuracy = 0.8724\n",
      "2024-11-12 08:38:13,525 - Time for epoch 17: 32.54s\n",
      "2024-11-12 08:38:43,791 - Epoch 18/25 - Training: Loss = 0.2620, Accuracy = 0.9105\n",
      "2024-11-12 08:38:45,934 - Epoch 18/25 - Validation: Loss = 0.3787, Accuracy = 0.8782\n",
      "2024-11-12 08:38:45,935 - Time for epoch 18: 32.41s\n",
      "2024-11-12 08:39:16,288 - Epoch 19/25 - Training: Loss = 0.2178, Accuracy = 0.9308\n",
      "2024-11-12 08:39:18,003 - Epoch 19/25 - Validation: Loss = 0.3852, Accuracy = 0.8799\n",
      "2024-11-12 08:39:18,004 - Time for epoch 19: 32.07s\n",
      "2024-11-12 08:39:50,042 - Epoch 20/25 - Training: Loss = 0.2104, Accuracy = 0.9288\n",
      "2024-11-12 08:39:51,740 - Epoch 20/25 - Validation: Loss = 0.3093, Accuracy = 0.8949\n",
      "2024-11-12 08:39:51,741 - Time for epoch 20: 33.74s\n",
      "2024-11-12 08:40:22,048 - Epoch 21/25 - Training: Loss = 0.1804, Accuracy = 0.9420\n",
      "2024-11-12 08:40:26,808 - Epoch 21/25 - Validation: Loss = 0.3274, Accuracy = 0.8999\n",
      "2024-11-12 08:40:26,809 - Time for epoch 21: 35.07s\n",
      "2024-11-12 08:40:57,529 - Epoch 22/25 - Training: Loss = 0.1755, Accuracy = 0.9422\n",
      "2024-11-12 08:40:59,243 - Epoch 22/25 - Validation: Loss = 0.3228, Accuracy = 0.8907\n",
      "2024-11-12 08:40:59,244 - Time for epoch 22: 32.43s\n",
      "2024-11-12 08:41:35,927 - Epoch 23/25 - Training: Loss = 0.1644, Accuracy = 0.9468\n",
      "2024-11-12 08:41:38,084 - Epoch 23/25 - Validation: Loss = 0.3115, Accuracy = 0.9083\n",
      "2024-11-12 08:41:38,086 - Time for epoch 23: 38.84s\n",
      "2024-11-12 08:42:29,272 - Epoch 24/25 - Training: Loss = 0.1484, Accuracy = 0.9524\n",
      "2024-11-12 08:42:37,156 - Epoch 24/25 - Validation: Loss = 0.2969, Accuracy = 0.9049\n",
      "2024-11-12 08:42:37,158 - Time for epoch 24: 59.07s\n",
      "2024-11-12 08:43:24,462 - Epoch 25/25 - Training: Loss = 0.1363, Accuracy = 0.9559\n",
      "2024-11-12 08:43:30,799 - Epoch 25/25 - Validation: Loss = 0.3044, Accuracy = 0.9016\n",
      "2024-11-12 08:43:30,801 - Time for epoch 25: 53.64s\n",
      "2024-11-12 08:43:30,802 - Total Training Time: 918.62s\n",
      "2024-11-12 08:43:35,835 - Macro-Averaged F1 Score: 0.9034\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using EfficientNet-B0\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.00005]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 9\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.efficientnet_b0(weights=None)\n",
    "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 01 EfficientNet_B0 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_01_EfficientNet_B0_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 01 EfficientNet_B0 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_01_EfficientNet_B0_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 01 EfficientNet_B0 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_01_EfficientNet_B0_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 01 EfficientNet_B0 Confusion Matrix\")\n",
    "                plt.savefig('dataset_01_EfficientNet_B0_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 01 EfficientNet_B0 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_01_EfficientNet_B0_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_01_efficientnet_b0_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Inception_V3 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 08:43:38,009 - Training dataset size: 10021\n",
      "2024-11-12 08:43:38,010 - Validation dataset size: 1199\n",
      "2024-11-12 08:43:38,010 - Test dataset size: 1342\n",
      "2024-11-12 08:43:38,012 - Training with Batch Size: 128, Learning Rate: 0.0005, Epochs: 25\n",
      "2024-11-12 08:44:38,479 - Epoch 1/25 - Training: Loss = 1.6780, Accuracy = 0.3784\n",
      "2024-11-12 08:44:41,941 - Epoch 1/25 - Validation: Loss = 1.6042, Accuracy = 0.3903\n",
      "2024-11-12 08:44:41,942 - Time for epoch 1: 60.18s\n",
      "2024-11-12 08:45:38,617 - Epoch 2/25 - Training: Loss = 1.3025, Accuracy = 0.5223\n",
      "2024-11-12 08:45:42,128 - Epoch 2/25 - Validation: Loss = 1.1845, Accuracy = 0.5888\n",
      "2024-11-12 08:45:42,130 - Time for epoch 2: 60.19s\n",
      "2024-11-12 08:46:38,387 - Epoch 3/25 - Training: Loss = 0.9261, Accuracy = 0.6677\n",
      "2024-11-12 08:46:41,982 - Epoch 3/25 - Validation: Loss = 0.9335, Accuracy = 0.6664\n",
      "2024-11-12 08:46:41,983 - Time for epoch 3: 59.85s\n",
      "2024-11-12 08:47:38,740 - Epoch 4/25 - Training: Loss = 0.6136, Accuracy = 0.7817\n",
      "2024-11-12 08:47:42,210 - Epoch 4/25 - Validation: Loss = 0.7585, Accuracy = 0.7631\n",
      "2024-11-12 08:47:42,211 - Time for epoch 4: 60.23s\n",
      "2024-11-12 08:48:39,630 - Epoch 5/25 - Training: Loss = 0.3863, Accuracy = 0.8670\n",
      "2024-11-12 08:48:43,094 - Epoch 5/25 - Validation: Loss = 0.4774, Accuracy = 0.8482\n",
      "2024-11-12 08:48:43,095 - Time for epoch 5: 60.88s\n",
      "2024-11-12 08:50:02,095 - Epoch 6/25 - Training: Loss = 0.2561, Accuracy = 0.9115\n",
      "2024-11-12 08:50:05,630 - Epoch 6/25 - Validation: Loss = 0.4654, Accuracy = 0.8490\n",
      "2024-11-12 08:50:05,631 - Time for epoch 6: 82.53s\n",
      "2024-11-12 08:51:00,579 - Epoch 7/25 - Training: Loss = 0.1443, Accuracy = 0.9514\n",
      "2024-11-12 08:51:04,041 - Epoch 7/25 - Validation: Loss = 0.4313, Accuracy = 0.8565\n",
      "2024-11-12 08:51:04,043 - Time for epoch 7: 58.41s\n",
      "2024-11-12 08:52:00,471 - Epoch 8/25 - Training: Loss = 0.1110, Accuracy = 0.9639\n",
      "2024-11-12 08:52:04,711 - Epoch 8/25 - Validation: Loss = 0.3250, Accuracy = 0.8941\n",
      "2024-11-12 08:52:04,713 - Time for epoch 8: 60.67s\n",
      "2024-11-12 08:53:10,218 - Epoch 9/25 - Training: Loss = 0.0890, Accuracy = 0.9699\n",
      "2024-11-12 08:53:13,771 - Epoch 9/25 - Validation: Loss = 0.2966, Accuracy = 0.9149\n",
      "2024-11-12 08:53:13,773 - Time for epoch 9: 69.06s\n",
      "2024-11-12 08:54:23,189 - Epoch 10/25 - Training: Loss = 0.0537, Accuracy = 0.9827\n",
      "2024-11-12 08:54:31,420 - Epoch 10/25 - Validation: Loss = 0.2018, Accuracy = 0.9358\n",
      "2024-11-12 08:54:31,422 - Time for epoch 10: 77.65s\n",
      "2024-11-12 08:56:01,176 - Epoch 11/25 - Training: Loss = 0.0412, Accuracy = 0.9869\n",
      "2024-11-12 08:56:19,248 - Epoch 11/25 - Validation: Loss = 0.1991, Accuracy = 0.9458\n",
      "2024-11-12 08:56:19,249 - Time for epoch 11: 107.83s\n",
      "2024-11-12 08:59:24,674 - Epoch 12/25 - Training: Loss = 0.0393, Accuracy = 0.9881\n",
      "2024-11-12 08:59:28,784 - Epoch 12/25 - Validation: Loss = 0.2749, Accuracy = 0.9258\n",
      "2024-11-12 08:59:28,785 - Time for epoch 12: 189.53s\n",
      "2024-11-12 09:00:25,889 - Epoch 13/25 - Training: Loss = 0.0404, Accuracy = 0.9876\n",
      "2024-11-12 09:00:30,244 - Epoch 13/25 - Validation: Loss = 0.2133, Accuracy = 0.9324\n",
      "2024-11-12 09:00:30,245 - Time for epoch 13: 61.46s\n",
      "2024-11-12 09:01:27,766 - Epoch 14/25 - Training: Loss = 0.0288, Accuracy = 0.9908\n",
      "2024-11-12 09:01:31,457 - Epoch 14/25 - Validation: Loss = 0.1750, Accuracy = 0.9416\n",
      "2024-11-12 09:01:31,458 - Time for epoch 14: 61.21s\n",
      "2024-11-12 09:02:31,145 - Epoch 15/25 - Training: Loss = 0.0176, Accuracy = 0.9942\n",
      "2024-11-12 09:02:34,576 - Epoch 15/25 - Validation: Loss = 0.2639, Accuracy = 0.9283\n",
      "2024-11-12 09:02:34,577 - Time for epoch 15: 63.12s\n",
      "2024-11-12 09:03:30,599 - Epoch 16/25 - Training: Loss = 0.0321, Accuracy = 0.9902\n",
      "2024-11-12 09:03:34,028 - Epoch 16/25 - Validation: Loss = 0.1452, Accuracy = 0.9525\n",
      "2024-11-12 09:03:34,029 - Time for epoch 16: 59.45s\n",
      "2024-11-12 09:05:46,962 - Epoch 17/25 - Training: Loss = 0.0298, Accuracy = 0.9901\n",
      "2024-11-12 09:05:50,445 - Epoch 17/25 - Validation: Loss = 0.2204, Accuracy = 0.9391\n",
      "2024-11-12 09:05:50,446 - Time for epoch 17: 136.42s\n",
      "2024-11-12 09:06:54,523 - Epoch 18/25 - Training: Loss = 0.0368, Accuracy = 0.9876\n",
      "2024-11-12 09:06:58,095 - Epoch 18/25 - Validation: Loss = 0.2038, Accuracy = 0.9450\n",
      "2024-11-12 09:06:58,096 - Time for epoch 18: 67.65s\n",
      "2024-11-12 09:07:57,914 - Epoch 19/25 - Training: Loss = 0.0228, Accuracy = 0.9926\n",
      "2024-11-12 09:08:01,786 - Epoch 19/25 - Validation: Loss = 0.1528, Accuracy = 0.9491\n",
      "2024-11-12 09:08:01,787 - Time for epoch 19: 63.69s\n",
      "2024-11-12 09:08:59,945 - Epoch 20/25 - Training: Loss = 0.0169, Accuracy = 0.9940\n",
      "2024-11-12 09:09:03,649 - Epoch 20/25 - Validation: Loss = 0.1752, Accuracy = 0.9575\n",
      "2024-11-12 09:09:03,650 - Time for epoch 20: 61.86s\n",
      "2024-11-12 09:09:58,857 - Epoch 21/25 - Training: Loss = 0.0217, Accuracy = 0.9931\n",
      "2024-11-12 09:10:02,444 - Epoch 21/25 - Validation: Loss = 0.1143, Accuracy = 0.9683\n",
      "2024-11-12 09:10:02,445 - Time for epoch 21: 58.79s\n",
      "2024-11-12 09:11:00,881 - Epoch 22/25 - Training: Loss = 0.0073, Accuracy = 0.9979\n",
      "2024-11-12 09:11:05,251 - Epoch 22/25 - Validation: Loss = 0.1084, Accuracy = 0.9725\n",
      "2024-11-12 09:11:05,252 - Time for epoch 22: 62.81s\n",
      "2024-11-12 09:11:59,868 - Epoch 23/25 - Training: Loss = 0.0056, Accuracy = 0.9982\n",
      "2024-11-12 09:12:04,038 - Epoch 23/25 - Validation: Loss = 0.1093, Accuracy = 0.9675\n",
      "2024-11-12 09:12:04,039 - Time for epoch 23: 58.79s\n",
      "2024-11-12 09:12:58,966 - Epoch 24/25 - Training: Loss = 0.0317, Accuracy = 0.9900\n",
      "2024-11-12 09:13:02,606 - Epoch 24/25 - Validation: Loss = 0.0843, Accuracy = 0.9700\n",
      "2024-11-12 09:13:02,607 - Time for epoch 24: 58.57s\n",
      "2024-11-12 09:13:58,065 - Epoch 25/25 - Training: Loss = 0.0359, Accuracy = 0.9884\n",
      "2024-11-12 09:14:02,789 - Epoch 25/25 - Validation: Loss = 0.0685, Accuracy = 0.9766\n",
      "2024-11-12 09:14:02,790 - Time for epoch 25: 60.18s\n",
      "2024-11-12 09:14:02,790 - Total Training Time: 1820.99s\n",
      "2024-11-12 09:14:07,754 - Macro-Averaged F1 Score: 0.9499\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using InceptionV3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset1_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.0005]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 9\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.inception_v3(weights=None, aux_logits=False, init_weights=True)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 01 Inception_V3 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_01_Inception_V3_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 01 Inception_V3 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_01_Inception_V3_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 01 Inception_V3 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_01_Inception_V3_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 01 Inception_V3 Confusion Matrix\")\n",
    "                plt.savefig('dataset_01_Inception_V3_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 01 Inception_V3 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_01_Inception_V3_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_01_inception_v3_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Dataset 02</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">VGG16 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 09:14:09,954 - Training dataset size: 8679\n",
      "2024-11-12 09:14:09,955 - Validation dataset size: 1034\n",
      "2024-11-12 09:14:09,955 - Test dataset size: 1199\n",
      "2024-11-12 09:14:09,956 - Training with Batch Size: 64, Learning Rate: 0.0001, Epochs: 25\n",
      "2024-11-12 09:15:05,256 - Epoch 1/25 - Training: Loss = 1.9505, Accuracy = 0.2923\n",
      "2024-11-12 09:15:07,712 - Epoch 1/25 - Validation: Loss = 1.5355, Accuracy = 0.4758\n",
      "2024-11-12 09:15:07,713 - Time for epoch 1: 56.62s\n",
      "2024-11-12 09:15:53,253 - Epoch 2/25 - Training: Loss = 1.3840, Accuracy = 0.5311\n",
      "2024-11-12 09:15:55,484 - Epoch 2/25 - Validation: Loss = 1.2367, Accuracy = 0.5977\n",
      "2024-11-12 09:15:55,485 - Time for epoch 2: 47.77s\n",
      "2024-11-12 09:16:50,213 - Epoch 3/25 - Training: Loss = 0.9277, Accuracy = 0.6872\n",
      "2024-11-12 09:16:55,239 - Epoch 3/25 - Validation: Loss = 0.8010, Accuracy = 0.7360\n",
      "2024-11-12 09:16:55,240 - Time for epoch 3: 59.75s\n",
      "2024-11-12 09:17:39,792 - Epoch 4/25 - Training: Loss = 0.6788, Accuracy = 0.7681\n",
      "2024-11-12 09:17:42,028 - Epoch 4/25 - Validation: Loss = 0.5866, Accuracy = 0.8085\n",
      "2024-11-12 09:17:42,029 - Time for epoch 4: 46.79s\n",
      "2024-11-12 09:18:32,307 - Epoch 5/25 - Training: Loss = 0.5023, Accuracy = 0.8317\n",
      "2024-11-12 09:18:34,527 - Epoch 5/25 - Validation: Loss = 0.4978, Accuracy = 0.8250\n",
      "2024-11-12 09:18:34,527 - Time for epoch 5: 52.50s\n",
      "2024-11-12 09:19:18,074 - Epoch 6/25 - Training: Loss = 0.3732, Accuracy = 0.8767\n",
      "2024-11-12 09:19:20,311 - Epoch 6/25 - Validation: Loss = 0.3744, Accuracy = 0.8704\n",
      "2024-11-12 09:19:20,312 - Time for epoch 6: 45.78s\n",
      "2024-11-12 09:20:06,399 - Epoch 7/25 - Training: Loss = 0.2663, Accuracy = 0.9098\n",
      "2024-11-12 09:20:10,425 - Epoch 7/25 - Validation: Loss = 0.4055, Accuracy = 0.8723\n",
      "2024-11-12 09:20:10,426 - Time for epoch 7: 50.11s\n",
      "2024-11-12 09:21:07,406 - Epoch 8/25 - Training: Loss = 0.1925, Accuracy = 0.9372\n",
      "2024-11-12 09:21:11,453 - Epoch 8/25 - Validation: Loss = 0.3897, Accuracy = 0.8936\n",
      "2024-11-12 09:21:11,455 - Time for epoch 8: 61.03s\n",
      "2024-11-12 09:22:14,312 - Epoch 9/25 - Training: Loss = 0.1565, Accuracy = 0.9499\n",
      "2024-11-12 09:22:16,536 - Epoch 9/25 - Validation: Loss = 0.3409, Accuracy = 0.9004\n",
      "2024-11-12 09:22:16,537 - Time for epoch 9: 65.08s\n",
      "2024-11-12 09:23:01,716 - Epoch 10/25 - Training: Loss = 0.1226, Accuracy = 0.9621\n",
      "2024-11-12 09:23:03,928 - Epoch 10/25 - Validation: Loss = 0.3777, Accuracy = 0.8888\n",
      "2024-11-12 09:23:03,929 - Time for epoch 10: 47.39s\n",
      "2024-11-12 09:23:47,551 - Epoch 11/25 - Training: Loss = 0.0837, Accuracy = 0.9725\n",
      "2024-11-12 09:23:49,856 - Epoch 11/25 - Validation: Loss = 0.2396, Accuracy = 0.9294\n",
      "2024-11-12 09:23:49,857 - Time for epoch 11: 45.93s\n",
      "2024-11-12 09:24:33,740 - Epoch 12/25 - Training: Loss = 0.0810, Accuracy = 0.9727\n",
      "2024-11-12 09:24:35,934 - Epoch 12/25 - Validation: Loss = 0.3134, Accuracy = 0.9197\n",
      "2024-11-12 09:24:35,935 - Time for epoch 12: 46.08s\n",
      "2024-11-12 09:25:19,661 - Epoch 13/25 - Training: Loss = 0.0731, Accuracy = 0.9785\n",
      "2024-11-12 09:25:21,851 - Epoch 13/25 - Validation: Loss = 0.1828, Accuracy = 0.9449\n",
      "2024-11-12 09:25:21,852 - Time for epoch 13: 45.91s\n",
      "2024-11-12 09:26:05,156 - Epoch 14/25 - Training: Loss = 0.0621, Accuracy = 0.9796\n",
      "2024-11-12 09:26:07,343 - Epoch 14/25 - Validation: Loss = 0.3090, Accuracy = 0.9178\n",
      "2024-11-12 09:26:07,344 - Time for epoch 14: 45.49s\n",
      "2024-11-12 09:26:52,127 - Epoch 15/25 - Training: Loss = 0.0589, Accuracy = 0.9818\n",
      "2024-11-12 09:26:54,589 - Epoch 15/25 - Validation: Loss = 0.3806, Accuracy = 0.8985\n",
      "2024-11-12 09:26:54,590 - Time for epoch 15: 47.24s\n",
      "2024-11-12 09:27:39,811 - Epoch 16/25 - Training: Loss = 0.0548, Accuracy = 0.9843\n",
      "2024-11-12 09:27:42,146 - Epoch 16/25 - Validation: Loss = 0.2361, Accuracy = 0.9352\n",
      "2024-11-12 09:27:42,147 - Time for epoch 16: 47.56s\n",
      "2024-11-12 09:28:27,344 - Epoch 17/25 - Training: Loss = 0.0528, Accuracy = 0.9834\n",
      "2024-11-12 09:28:29,545 - Epoch 17/25 - Validation: Loss = 0.2522, Accuracy = 0.9313\n",
      "2024-11-12 09:28:29,546 - Time for epoch 17: 47.40s\n",
      "2024-11-12 09:29:12,378 - Epoch 18/25 - Training: Loss = 0.0323, Accuracy = 0.9886\n",
      "2024-11-12 09:29:14,605 - Epoch 18/25 - Validation: Loss = 0.2398, Accuracy = 0.9420\n",
      "2024-11-12 09:29:14,606 - Time for epoch 18: 45.06s\n",
      "2024-11-12 09:29:59,043 - Epoch 19/25 - Training: Loss = 0.0389, Accuracy = 0.9865\n",
      "2024-11-12 09:30:01,486 - Epoch 19/25 - Validation: Loss = 0.2061, Accuracy = 0.9429\n",
      "2024-11-12 09:30:01,487 - Time for epoch 19: 46.88s\n",
      "2024-11-12 09:30:45,237 - Epoch 20/25 - Training: Loss = 0.0356, Accuracy = 0.9897\n",
      "2024-11-12 09:30:48,316 - Epoch 20/25 - Validation: Loss = 0.2531, Accuracy = 0.9391\n",
      "2024-11-12 09:30:48,317 - Time for epoch 20: 46.83s\n",
      "2024-11-12 09:31:41,951 - Epoch 21/25 - Training: Loss = 0.0251, Accuracy = 0.9915\n",
      "2024-11-12 09:31:44,441 - Epoch 21/25 - Validation: Loss = 0.1999, Accuracy = 0.9487\n",
      "2024-11-12 09:31:44,442 - Time for epoch 21: 56.12s\n",
      "2024-11-12 09:32:27,201 - Epoch 22/25 - Training: Loss = 0.0537, Accuracy = 0.9850\n",
      "2024-11-12 09:32:33,906 - Epoch 22/25 - Validation: Loss = 0.2669, Accuracy = 0.9362\n",
      "2024-11-12 09:32:33,907 - Time for epoch 22: 49.46s\n",
      "2024-11-12 09:33:18,874 - Epoch 23/25 - Training: Loss = 0.0330, Accuracy = 0.9908\n",
      "2024-11-12 09:33:21,065 - Epoch 23/25 - Validation: Loss = 0.1945, Accuracy = 0.9429\n",
      "2024-11-12 09:33:21,067 - Time for epoch 23: 47.16s\n",
      "2024-11-12 09:34:09,094 - Epoch 24/25 - Training: Loss = 0.0280, Accuracy = 0.9912\n",
      "2024-11-12 09:34:11,310 - Epoch 24/25 - Validation: Loss = 0.1868, Accuracy = 0.9536\n",
      "2024-11-12 09:34:11,311 - Time for epoch 24: 50.24s\n",
      "2024-11-12 09:34:56,943 - Epoch 25/25 - Training: Loss = 0.0340, Accuracy = 0.9901\n",
      "2024-11-12 09:35:00,391 - Epoch 25/25 - Validation: Loss = 0.2432, Accuracy = 0.9284\n",
      "2024-11-12 09:35:00,392 - Time for epoch 25: 49.08s\n",
      "2024-11-12 09:35:00,392 - Total Training Time: 1249.26s\n",
      "2024-11-12 09:35:07,738 - Macro-Averaged F1 Score: 0.9326\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using VGG16\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.0001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.vgg16(weights=None)\n",
    "            model.classifier[6] = nn.Linear(model.classifier[6].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 02 VGG16 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_02_vgg16_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 02 VGG16 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_02_vgg16_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 02 VGG16 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_02_vgg16_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 02 VGG16 Confusion Matrix\")\n",
    "                plt.savefig('dataset_02_vgg16_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 02 VGG16 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_02_vgg16_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_02_vgg16_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">ResNet50 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 09:35:10,713 - Training dataset size: 8679\n",
      "2024-11-12 09:35:10,714 - Validation dataset size: 1034\n",
      "2024-11-12 09:35:10,714 - Test dataset size: 1199\n",
      "2024-11-12 09:35:10,715 - Training with Batch Size: 64, Learning Rate: 0.0001, Epochs: 25\n",
      "2024-11-12 09:35:54,253 - Epoch 1/25 - Training: Loss = 1.8732, Accuracy = 0.3113\n",
      "2024-11-12 09:35:55,997 - Epoch 1/25 - Validation: Loss = 1.8838, Accuracy = 0.3462\n",
      "2024-11-12 09:35:55,998 - Time for epoch 1: 45.06s\n",
      "2024-11-12 09:36:58,113 - Epoch 2/25 - Training: Loss = 1.5382, Accuracy = 0.4464\n",
      "2024-11-12 09:37:01,958 - Epoch 2/25 - Validation: Loss = 1.5951, Accuracy = 0.4091\n",
      "2024-11-12 09:37:01,959 - Time for epoch 2: 65.96s\n",
      "2024-11-12 09:37:53,464 - Epoch 3/25 - Training: Loss = 1.2945, Accuracy = 0.5389\n",
      "2024-11-12 09:38:00,456 - Epoch 3/25 - Validation: Loss = 1.1864, Accuracy = 0.5667\n",
      "2024-11-12 09:38:00,457 - Time for epoch 3: 58.50s\n",
      "2024-11-12 09:38:47,193 - Epoch 4/25 - Training: Loss = 1.0711, Accuracy = 0.6200\n",
      "2024-11-12 09:38:48,979 - Epoch 4/25 - Validation: Loss = 1.2841, Accuracy = 0.5774\n",
      "2024-11-12 09:38:48,979 - Time for epoch 4: 48.52s\n",
      "2024-11-12 09:39:22,070 - Epoch 5/25 - Training: Loss = 0.8541, Accuracy = 0.7023\n",
      "2024-11-12 09:39:23,795 - Epoch 5/25 - Validation: Loss = 0.9456, Accuracy = 0.6750\n",
      "2024-11-12 09:39:23,796 - Time for epoch 5: 34.82s\n",
      "2024-11-12 09:39:59,887 - Epoch 6/25 - Training: Loss = 0.6631, Accuracy = 0.7772\n",
      "2024-11-12 09:40:01,836 - Epoch 6/25 - Validation: Loss = 0.7123, Accuracy = 0.7534\n",
      "2024-11-12 09:40:01,837 - Time for epoch 6: 38.04s\n",
      "2024-11-12 09:40:32,273 - Epoch 7/25 - Training: Loss = 0.5059, Accuracy = 0.8281\n",
      "2024-11-12 09:40:33,970 - Epoch 7/25 - Validation: Loss = 0.7483, Accuracy = 0.7282\n",
      "2024-11-12 09:40:33,971 - Time for epoch 7: 32.13s\n",
      "2024-11-12 09:41:01,664 - Epoch 8/25 - Training: Loss = 0.4007, Accuracy = 0.8650\n",
      "2024-11-12 09:41:03,351 - Epoch 8/25 - Validation: Loss = 0.6845, Accuracy = 0.7805\n",
      "2024-11-12 09:41:03,352 - Time for epoch 8: 29.38s\n",
      "2024-11-12 09:41:32,483 - Epoch 9/25 - Training: Loss = 0.3068, Accuracy = 0.8956\n",
      "2024-11-12 09:41:34,194 - Epoch 9/25 - Validation: Loss = 0.4795, Accuracy = 0.8356\n",
      "2024-11-12 09:41:34,195 - Time for epoch 9: 30.84s\n",
      "2024-11-12 09:42:08,484 - Epoch 10/25 - Training: Loss = 0.2313, Accuracy = 0.9245\n",
      "2024-11-12 09:42:10,245 - Epoch 10/25 - Validation: Loss = 0.4498, Accuracy = 0.8453\n",
      "2024-11-12 09:42:10,246 - Time for epoch 10: 36.05s\n",
      "2024-11-12 09:42:45,842 - Epoch 11/25 - Training: Loss = 0.1675, Accuracy = 0.9472\n",
      "2024-11-12 09:42:47,615 - Epoch 11/25 - Validation: Loss = 0.4626, Accuracy = 0.8501\n",
      "2024-11-12 09:42:47,615 - Time for epoch 11: 37.37s\n",
      "2024-11-12 09:43:15,446 - Epoch 12/25 - Training: Loss = 0.1082, Accuracy = 0.9676\n",
      "2024-11-12 09:43:18,995 - Epoch 12/25 - Validation: Loss = 0.3457, Accuracy = 0.8849\n",
      "2024-11-12 09:43:18,996 - Time for epoch 12: 31.38s\n",
      "2024-11-12 09:43:55,039 - Epoch 13/25 - Training: Loss = 0.1061, Accuracy = 0.9679\n",
      "2024-11-12 09:43:57,193 - Epoch 13/25 - Validation: Loss = 0.2859, Accuracy = 0.9043\n",
      "2024-11-12 09:43:57,194 - Time for epoch 13: 38.20s\n",
      "2024-11-12 09:44:42,751 - Epoch 14/25 - Training: Loss = 0.0707, Accuracy = 0.9808\n",
      "2024-11-12 09:44:48,362 - Epoch 14/25 - Validation: Loss = 0.4140, Accuracy = 0.8675\n",
      "2024-11-12 09:44:48,363 - Time for epoch 14: 51.17s\n",
      "2024-11-12 09:45:21,907 - Epoch 15/25 - Training: Loss = 0.0956, Accuracy = 0.9714\n",
      "2024-11-12 09:45:23,700 - Epoch 15/25 - Validation: Loss = 0.2466, Accuracy = 0.9197\n",
      "2024-11-12 09:45:23,701 - Time for epoch 15: 35.34s\n",
      "2024-11-12 09:45:57,275 - Epoch 16/25 - Training: Loss = 0.0675, Accuracy = 0.9785\n",
      "2024-11-12 09:45:58,996 - Epoch 16/25 - Validation: Loss = 0.2538, Accuracy = 0.9217\n",
      "2024-11-12 09:45:58,996 - Time for epoch 16: 35.29s\n",
      "2024-11-12 09:46:29,776 - Epoch 17/25 - Training: Loss = 0.0458, Accuracy = 0.9876\n",
      "2024-11-12 09:46:31,508 - Epoch 17/25 - Validation: Loss = 0.2352, Accuracy = 0.9284\n",
      "2024-11-12 09:46:31,509 - Time for epoch 17: 32.51s\n",
      "2024-11-12 09:47:01,121 - Epoch 18/25 - Training: Loss = 0.0376, Accuracy = 0.9894\n",
      "2024-11-12 09:47:02,950 - Epoch 18/25 - Validation: Loss = 0.2746, Accuracy = 0.9255\n",
      "2024-11-12 09:47:02,951 - Time for epoch 18: 31.44s\n",
      "2024-11-12 09:47:34,047 - Epoch 19/25 - Training: Loss = 0.0466, Accuracy = 0.9848\n",
      "2024-11-12 09:47:35,770 - Epoch 19/25 - Validation: Loss = 0.2908, Accuracy = 0.9014\n",
      "2024-11-12 09:47:35,771 - Time for epoch 19: 32.82s\n",
      "2024-11-12 09:48:03,551 - Epoch 20/25 - Training: Loss = 0.0538, Accuracy = 0.9828\n",
      "2024-11-12 09:48:05,265 - Epoch 20/25 - Validation: Loss = 0.3095, Accuracy = 0.9120\n",
      "2024-11-12 09:48:05,266 - Time for epoch 20: 29.49s\n",
      "2024-11-12 09:48:39,329 - Epoch 21/25 - Training: Loss = 0.0453, Accuracy = 0.9861\n",
      "2024-11-12 09:48:41,063 - Epoch 21/25 - Validation: Loss = 0.2171, Accuracy = 0.9381\n",
      "2024-11-12 09:48:41,063 - Time for epoch 21: 35.80s\n",
      "2024-11-12 09:49:10,431 - Epoch 22/25 - Training: Loss = 0.0397, Accuracy = 0.9876\n",
      "2024-11-12 09:49:13,016 - Epoch 22/25 - Validation: Loss = 0.1998, Accuracy = 0.9381\n",
      "2024-11-12 09:49:13,017 - Time for epoch 22: 31.95s\n",
      "2024-11-12 09:49:42,886 - Epoch 23/25 - Training: Loss = 0.0344, Accuracy = 0.9888\n",
      "2024-11-12 09:49:44,565 - Epoch 23/25 - Validation: Loss = 0.4853, Accuracy = 0.9130\n",
      "2024-11-12 09:49:44,566 - Time for epoch 23: 31.55s\n",
      "2024-11-12 09:50:13,358 - Epoch 24/25 - Training: Loss = 0.0469, Accuracy = 0.9849\n",
      "2024-11-12 09:50:15,250 - Epoch 24/25 - Validation: Loss = 0.2927, Accuracy = 0.9110\n",
      "2024-11-12 09:50:15,250 - Time for epoch 24: 30.68s\n",
      "2024-11-12 09:50:45,841 - Epoch 25/25 - Training: Loss = 0.0344, Accuracy = 0.9893\n",
      "2024-11-12 09:50:47,538 - Epoch 25/25 - Validation: Loss = 0.2895, Accuracy = 0.9178\n",
      "2024-11-12 09:50:47,539 - Time for epoch 25: 32.29s\n",
      "2024-11-12 09:50:47,539 - Total Training Time: 936.57s\n",
      "2024-11-12 09:50:53,365 - Macro-Averaged F1 Score: 0.9299\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using ResNet50\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.0001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.resnet50(weights=None)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 02 ResNet50 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_02_resnet50_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 02 ResNet50 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_02_resnet50_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 02 ResNet50 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_02_resnet50_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 02 ResNet50 Confusion Matrix\")\n",
    "                plt.savefig('dataset_02_resnet50_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 02 ResNet50 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_02_resnet50_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_02_resnet50_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">EfficientNet_B0 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 09:50:55,786 - Training dataset size: 8679\n",
      "2024-11-12 09:50:55,786 - Validation dataset size: 1034\n",
      "2024-11-12 09:50:55,787 - Test dataset size: 1199\n",
      "2024-11-12 09:50:55,788 - Training with Batch Size: 64, Learning Rate: 0.0001, Epochs: 25\n",
      "2024-11-12 09:51:21,986 - Epoch 1/25 - Training: Loss = 2.1090, Accuracy = 0.2306\n",
      "2024-11-12 09:51:23,380 - Epoch 1/25 - Validation: Loss = 1.8878, Accuracy = 0.3172\n",
      "2024-11-12 09:51:23,381 - Time for epoch 1: 27.51s\n",
      "2024-11-12 09:51:49,772 - Epoch 2/25 - Training: Loss = 1.8048, Accuracy = 0.3381\n",
      "2024-11-12 09:51:51,927 - Epoch 2/25 - Validation: Loss = 1.7354, Accuracy = 0.3897\n",
      "2024-11-12 09:51:51,928 - Time for epoch 2: 28.55s\n",
      "2024-11-12 09:52:24,200 - Epoch 3/25 - Training: Loss = 1.5720, Accuracy = 0.4352\n",
      "2024-11-12 09:52:29,049 - Epoch 3/25 - Validation: Loss = 1.4618, Accuracy = 0.4632\n",
      "2024-11-12 09:52:29,050 - Time for epoch 3: 37.12s\n",
      "2024-11-12 09:52:59,936 - Epoch 4/25 - Training: Loss = 1.3375, Accuracy = 0.5211\n",
      "2024-11-12 09:53:01,532 - Epoch 4/25 - Validation: Loss = 1.2299, Accuracy = 0.5503\n",
      "2024-11-12 09:53:01,532 - Time for epoch 4: 32.48s\n",
      "2024-11-12 09:53:28,025 - Epoch 5/25 - Training: Loss = 1.1294, Accuracy = 0.5974\n",
      "2024-11-12 09:53:29,449 - Epoch 5/25 - Validation: Loss = 0.9604, Accuracy = 0.6499\n",
      "2024-11-12 09:53:29,450 - Time for epoch 5: 27.92s\n",
      "2024-11-12 09:53:55,775 - Epoch 6/25 - Training: Loss = 0.9364, Accuracy = 0.6719\n",
      "2024-11-12 09:53:57,306 - Epoch 6/25 - Validation: Loss = 0.7867, Accuracy = 0.7253\n",
      "2024-11-12 09:53:57,306 - Time for epoch 6: 27.86s\n",
      "2024-11-12 09:54:26,122 - Epoch 7/25 - Training: Loss = 0.7424, Accuracy = 0.7383\n",
      "2024-11-12 09:54:27,548 - Epoch 7/25 - Validation: Loss = 0.6225, Accuracy = 0.7930\n",
      "2024-11-12 09:54:27,548 - Time for epoch 7: 30.24s\n",
      "2024-11-12 09:55:01,528 - Epoch 8/25 - Training: Loss = 0.6115, Accuracy = 0.7903\n",
      "2024-11-12 09:55:02,956 - Epoch 8/25 - Validation: Loss = 0.5472, Accuracy = 0.8104\n",
      "2024-11-12 09:55:02,957 - Time for epoch 8: 35.41s\n",
      "2024-11-12 09:55:29,524 - Epoch 9/25 - Training: Loss = 0.5081, Accuracy = 0.8244\n",
      "2024-11-12 09:55:30,969 - Epoch 9/25 - Validation: Loss = 0.5502, Accuracy = 0.8153\n",
      "2024-11-12 09:55:30,970 - Time for epoch 9: 28.01s\n",
      "2024-11-12 09:55:59,537 - Epoch 10/25 - Training: Loss = 0.4307, Accuracy = 0.8513\n",
      "2024-11-12 09:56:01,010 - Epoch 10/25 - Validation: Loss = 0.4007, Accuracy = 0.8636\n",
      "2024-11-12 09:56:01,011 - Time for epoch 10: 30.04s\n",
      "2024-11-12 09:56:27,694 - Epoch 11/25 - Training: Loss = 0.3352, Accuracy = 0.8864\n",
      "2024-11-12 09:56:29,360 - Epoch 11/25 - Validation: Loss = 0.4144, Accuracy = 0.8685\n",
      "2024-11-12 09:56:29,361 - Time for epoch 11: 28.35s\n",
      "2024-11-12 09:56:56,223 - Epoch 12/25 - Training: Loss = 0.2854, Accuracy = 0.9062\n",
      "2024-11-12 09:56:57,661 - Epoch 12/25 - Validation: Loss = 0.3929, Accuracy = 0.8723\n",
      "2024-11-12 09:56:57,662 - Time for epoch 12: 28.30s\n",
      "2024-11-12 09:57:24,633 - Epoch 13/25 - Training: Loss = 0.2518, Accuracy = 0.9154\n",
      "2024-11-12 09:57:26,275 - Epoch 13/25 - Validation: Loss = 0.3188, Accuracy = 0.8907\n",
      "2024-11-12 09:57:26,276 - Time for epoch 13: 28.61s\n",
      "2024-11-12 09:57:53,625 - Epoch 14/25 - Training: Loss = 0.2192, Accuracy = 0.9294\n",
      "2024-11-12 09:57:55,063 - Epoch 14/25 - Validation: Loss = 0.3385, Accuracy = 0.8820\n",
      "2024-11-12 09:57:55,064 - Time for epoch 14: 28.79s\n",
      "2024-11-12 09:58:25,321 - Epoch 15/25 - Training: Loss = 0.1836, Accuracy = 0.9378\n",
      "2024-11-12 09:58:26,936 - Epoch 15/25 - Validation: Loss = 0.3063, Accuracy = 0.8975\n",
      "2024-11-12 09:58:26,937 - Time for epoch 15: 31.87s\n",
      "2024-11-12 09:58:55,323 - Epoch 16/25 - Training: Loss = 0.1640, Accuracy = 0.9469\n",
      "2024-11-12 09:58:56,850 - Epoch 16/25 - Validation: Loss = 0.3412, Accuracy = 0.8849\n",
      "2024-11-12 09:58:56,851 - Time for epoch 16: 29.91s\n",
      "2024-11-12 09:59:22,766 - Epoch 17/25 - Training: Loss = 0.1481, Accuracy = 0.9511\n",
      "2024-11-12 09:59:24,369 - Epoch 17/25 - Validation: Loss = 0.3233, Accuracy = 0.9004\n",
      "2024-11-12 09:59:24,369 - Time for epoch 17: 27.52s\n",
      "2024-11-12 10:00:20,695 - Epoch 18/25 - Training: Loss = 0.1357, Accuracy = 0.9588\n",
      "2024-11-12 10:00:22,153 - Epoch 18/25 - Validation: Loss = 0.2615, Accuracy = 0.9120\n",
      "2024-11-12 10:00:22,154 - Time for epoch 18: 57.78s\n",
      "2024-11-12 10:01:10,170 - Epoch 19/25 - Training: Loss = 0.1171, Accuracy = 0.9623\n",
      "2024-11-12 10:01:11,780 - Epoch 19/25 - Validation: Loss = 0.3300, Accuracy = 0.9081\n",
      "2024-11-12 10:01:11,781 - Time for epoch 19: 49.63s\n",
      "2024-11-12 10:01:44,390 - Epoch 20/25 - Training: Loss = 0.1107, Accuracy = 0.9642\n",
      "2024-11-12 10:01:46,146 - Epoch 20/25 - Validation: Loss = 0.2972, Accuracy = 0.9091\n",
      "2024-11-12 10:01:46,147 - Time for epoch 20: 34.37s\n",
      "2024-11-12 10:02:15,913 - Epoch 21/25 - Training: Loss = 0.0940, Accuracy = 0.9692\n",
      "2024-11-12 10:02:18,884 - Epoch 21/25 - Validation: Loss = 0.2971, Accuracy = 0.9149\n",
      "2024-11-12 10:02:18,884 - Time for epoch 21: 32.74s\n",
      "2024-11-12 10:02:57,181 - Epoch 22/25 - Training: Loss = 0.0942, Accuracy = 0.9685\n",
      "2024-11-12 10:02:58,716 - Epoch 22/25 - Validation: Loss = 0.2642, Accuracy = 0.9226\n",
      "2024-11-12 10:02:58,717 - Time for epoch 22: 39.83s\n",
      "2024-11-12 10:03:51,705 - Epoch 23/25 - Training: Loss = 0.0774, Accuracy = 0.9775\n",
      "2024-11-12 10:03:53,168 - Epoch 23/25 - Validation: Loss = 0.2401, Accuracy = 0.9323\n",
      "2024-11-12 10:03:53,170 - Time for epoch 23: 54.45s\n",
      "2024-11-12 10:04:20,303 - Epoch 24/25 - Training: Loss = 0.0772, Accuracy = 0.9747\n",
      "2024-11-12 10:04:21,747 - Epoch 24/25 - Validation: Loss = 0.2432, Accuracy = 0.9313\n",
      "2024-11-12 10:04:21,748 - Time for epoch 24: 28.58s\n",
      "2024-11-12 10:04:50,303 - Epoch 25/25 - Training: Loss = 0.0794, Accuracy = 0.9764\n",
      "2024-11-12 10:04:51,771 - Epoch 25/25 - Validation: Loss = 0.2565, Accuracy = 0.9236\n",
      "2024-11-12 10:04:51,772 - Time for epoch 25: 30.02s\n",
      "2024-11-12 10:04:51,773 - Total Training Time: 835.88s\n",
      "2024-11-12 10:04:54,173 - Macro-Averaged F1 Score: 0.9282\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using EfficientNet-B0\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.0001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.efficientnet_b0(weights=None)\n",
    "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 02 EfficientNet_B0 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_02_EfficientNet_B0_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 02 EfficientNet_B0 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_02_EfficientNet_B0_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 02 EfficientNet_B0 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_02_EfficientNet_B0_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 02 EfficientNet_B0 Confusion Matrix\")\n",
    "                plt.savefig('dataset_02_EfficientNet_B0_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 02 EfficientNet_B0 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_02_EfficientNet_B0_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_02_efficientnet_b0_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Inception_V3 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 10:04:56,255 - Training dataset size: 8679\n",
      "2024-11-12 10:04:56,256 - Validation dataset size: 1034\n",
      "2024-11-12 10:04:56,256 - Test dataset size: 1199\n",
      "2024-11-12 10:04:56,258 - Training with Batch Size: 128, Learning Rate: 0.0005, Epochs: 25\n",
      "2024-11-12 10:05:48,995 - Epoch 1/25 - Training: Loss = 1.7009, Accuracy = 0.3870\n",
      "2024-11-12 10:05:52,066 - Epoch 1/25 - Validation: Loss = 1.5402, Accuracy = 0.4342\n",
      "2024-11-12 10:05:52,067 - Time for epoch 1: 55.48s\n",
      "2024-11-12 10:06:40,497 - Epoch 2/25 - Training: Loss = 1.2991, Accuracy = 0.5267\n",
      "2024-11-12 10:06:44,465 - Epoch 2/25 - Validation: Loss = 1.5201, Accuracy = 0.5261\n",
      "2024-11-12 10:06:44,466 - Time for epoch 2: 52.40s\n",
      "2024-11-12 10:07:33,421 - Epoch 3/25 - Training: Loss = 0.9934, Accuracy = 0.6434\n",
      "2024-11-12 10:07:37,134 - Epoch 3/25 - Validation: Loss = 0.9782, Accuracy = 0.6644\n",
      "2024-11-12 10:07:37,135 - Time for epoch 3: 52.67s\n",
      "2024-11-12 10:08:32,676 - Epoch 4/25 - Training: Loss = 0.7386, Accuracy = 0.7365\n",
      "2024-11-12 10:08:36,674 - Epoch 4/25 - Validation: Loss = 1.0332, Accuracy = 0.6547\n",
      "2024-11-12 10:08:36,675 - Time for epoch 4: 59.54s\n",
      "2024-11-12 10:09:29,815 - Epoch 5/25 - Training: Loss = 0.5437, Accuracy = 0.8110\n",
      "2024-11-12 10:09:33,468 - Epoch 5/25 - Validation: Loss = 0.8146, Accuracy = 0.7553\n",
      "2024-11-12 10:09:33,469 - Time for epoch 5: 56.79s\n",
      "2024-11-12 10:10:23,703 - Epoch 6/25 - Training: Loss = 0.4137, Accuracy = 0.8584\n",
      "2024-11-12 10:10:26,799 - Epoch 6/25 - Validation: Loss = 0.7673, Accuracy = 0.7292\n",
      "2024-11-12 10:10:26,801 - Time for epoch 6: 53.33s\n",
      "2024-11-12 10:11:16,343 - Epoch 7/25 - Training: Loss = 0.3066, Accuracy = 0.8938\n",
      "2024-11-12 10:11:19,562 - Epoch 7/25 - Validation: Loss = 0.5613, Accuracy = 0.8066\n",
      "2024-11-12 10:11:19,563 - Time for epoch 7: 52.76s\n",
      "2024-11-12 10:12:12,275 - Epoch 8/25 - Training: Loss = 0.2150, Accuracy = 0.9281\n",
      "2024-11-12 10:12:15,472 - Epoch 8/25 - Validation: Loss = 0.5548, Accuracy = 0.8443\n",
      "2024-11-12 10:12:15,474 - Time for epoch 8: 55.91s\n",
      "2024-11-12 10:13:04,983 - Epoch 9/25 - Training: Loss = 0.1757, Accuracy = 0.9417\n",
      "2024-11-12 10:13:09,260 - Epoch 9/25 - Validation: Loss = 0.4358, Accuracy = 0.8540\n",
      "2024-11-12 10:13:09,261 - Time for epoch 9: 53.79s\n",
      "2024-11-12 10:14:06,878 - Epoch 10/25 - Training: Loss = 0.1453, Accuracy = 0.9517\n",
      "2024-11-12 10:14:10,025 - Epoch 10/25 - Validation: Loss = 0.3848, Accuracy = 0.8733\n",
      "2024-11-12 10:14:10,026 - Time for epoch 10: 60.76s\n",
      "2024-11-12 10:15:00,779 - Epoch 11/25 - Training: Loss = 0.1333, Accuracy = 0.9546\n",
      "2024-11-12 10:15:03,985 - Epoch 11/25 - Validation: Loss = 0.3884, Accuracy = 0.8714\n",
      "2024-11-12 10:15:03,986 - Time for epoch 11: 53.96s\n",
      "2024-11-12 10:16:18,067 - Epoch 12/25 - Training: Loss = 0.0905, Accuracy = 0.9682\n",
      "2024-11-12 10:16:24,768 - Epoch 12/25 - Validation: Loss = 0.3626, Accuracy = 0.8752\n",
      "2024-11-12 10:16:24,770 - Time for epoch 12: 80.78s\n",
      "2024-11-12 10:17:26,120 - Epoch 13/25 - Training: Loss = 0.0649, Accuracy = 0.9798\n",
      "2024-11-12 10:17:29,333 - Epoch 13/25 - Validation: Loss = 0.2488, Accuracy = 0.9178\n",
      "2024-11-12 10:17:29,335 - Time for epoch 13: 64.56s\n",
      "2024-11-12 10:18:19,221 - Epoch 14/25 - Training: Loss = 0.0615, Accuracy = 0.9789\n",
      "2024-11-12 10:18:23,773 - Epoch 14/25 - Validation: Loss = 0.3245, Accuracy = 0.8956\n",
      "2024-11-12 10:18:23,774 - Time for epoch 14: 54.44s\n",
      "2024-11-12 10:19:12,347 - Epoch 15/25 - Training: Loss = 0.0777, Accuracy = 0.9756\n",
      "2024-11-12 10:19:15,373 - Epoch 15/25 - Validation: Loss = 0.3391, Accuracy = 0.8946\n",
      "2024-11-12 10:19:15,374 - Time for epoch 15: 51.60s\n",
      "2024-11-12 10:20:05,061 - Epoch 16/25 - Training: Loss = 0.0587, Accuracy = 0.9794\n",
      "2024-11-12 10:20:08,160 - Epoch 16/25 - Validation: Loss = 0.3876, Accuracy = 0.8878\n",
      "2024-11-12 10:20:08,161 - Time for epoch 16: 52.79s\n",
      "2024-11-12 10:20:57,012 - Epoch 17/25 - Training: Loss = 0.0527, Accuracy = 0.9831\n",
      "2024-11-12 10:21:00,104 - Epoch 17/25 - Validation: Loss = 0.2220, Accuracy = 0.9313\n",
      "2024-11-12 10:21:00,104 - Time for epoch 17: 51.94s\n",
      "2024-11-12 10:21:53,966 - Epoch 18/25 - Training: Loss = 0.0304, Accuracy = 0.9900\n",
      "2024-11-12 10:22:02,772 - Epoch 18/25 - Validation: Loss = 0.2176, Accuracy = 0.9371\n",
      "2024-11-12 10:22:02,773 - Time for epoch 18: 62.67s\n",
      "2024-11-12 10:23:06,365 - Epoch 19/25 - Training: Loss = 0.0340, Accuracy = 0.9894\n",
      "2024-11-12 10:23:09,442 - Epoch 19/25 - Validation: Loss = 0.2584, Accuracy = 0.9188\n",
      "2024-11-12 10:23:09,443 - Time for epoch 19: 66.67s\n",
      "2024-11-12 10:24:16,314 - Epoch 20/25 - Training: Loss = 0.0294, Accuracy = 0.9894\n",
      "2024-11-12 10:24:19,497 - Epoch 20/25 - Validation: Loss = 0.2187, Accuracy = 0.9255\n",
      "2024-11-12 10:24:19,498 - Time for epoch 20: 70.05s\n",
      "2024-11-12 10:25:08,697 - Epoch 21/25 - Training: Loss = 0.0202, Accuracy = 0.9927\n",
      "2024-11-12 10:25:11,925 - Epoch 21/25 - Validation: Loss = 0.2051, Accuracy = 0.9468\n",
      "2024-11-12 10:25:11,926 - Time for epoch 21: 52.43s\n",
      "2024-11-12 10:26:01,145 - Epoch 22/25 - Training: Loss = 0.0243, Accuracy = 0.9922\n",
      "2024-11-12 10:26:04,258 - Epoch 22/25 - Validation: Loss = 0.2333, Accuracy = 0.9333\n",
      "2024-11-12 10:26:04,260 - Time for epoch 22: 52.33s\n",
      "2024-11-12 10:26:53,055 - Epoch 23/25 - Training: Loss = 0.0235, Accuracy = 0.9927\n",
      "2024-11-12 10:26:56,925 - Epoch 23/25 - Validation: Loss = 0.2337, Accuracy = 0.9236\n",
      "2024-11-12 10:26:56,926 - Time for epoch 23: 52.66s\n",
      "2024-11-12 10:27:46,915 - Epoch 24/25 - Training: Loss = 0.0298, Accuracy = 0.9906\n",
      "2024-11-12 10:27:49,967 - Epoch 24/25 - Validation: Loss = 0.2267, Accuracy = 0.9284\n",
      "2024-11-12 10:27:49,967 - Time for epoch 24: 53.04s\n",
      "2024-11-12 10:28:39,335 - Epoch 25/25 - Training: Loss = 0.0435, Accuracy = 0.9844\n",
      "2024-11-12 10:28:42,464 - Epoch 25/25 - Validation: Loss = 0.2528, Accuracy = 0.9246\n",
      "2024-11-12 10:28:42,465 - Time for epoch 25: 52.50s\n",
      "2024-11-12 10:28:42,466 - Total Training Time: 1425.84s\n",
      "2024-11-12 10:28:48,486 - Macro-Averaged F1 Score: 0.9177\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using InceptionV3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset2_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.0005]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.inception_v3(weights=None, aux_logits=False, init_weights=True)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 02 Inception_V3 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_02_Inception_V3_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 02 Inception_V3 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_02_Inception_V3_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 02 Inception_V3 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_02_Inception_V3_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 02 Inception_V3 Confusion Matrix\")\n",
    "                plt.savefig('dataset_02_Inception_V3_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 02 Inception_V3 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_02_Inception_V3_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_02_inception_v3_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Dataset 03</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">VGG16 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 10:28:51,383 - Training dataset size: 11594\n",
      "2024-11-12 10:28:51,384 - Validation dataset size: 1408\n",
      "2024-11-12 10:28:51,384 - Test dataset size: 1529\n",
      "2024-11-12 10:28:51,386 - Training with Batch Size: 128, Learning Rate: 1e-05, Epochs: 25\n",
      "2024-11-12 10:30:09,520 - Epoch 1/25 - Training: Loss = 1.9355, Accuracy = 0.2364\n",
      "2024-11-12 10:30:14,989 - Epoch 1/25 - Validation: Loss = 1.5127, Accuracy = 0.4766\n",
      "2024-11-12 10:30:14,990 - Time for epoch 1: 82.47s\n",
      "2024-11-12 10:31:12,808 - Epoch 2/25 - Training: Loss = 1.2974, Accuracy = 0.4799\n",
      "2024-11-12 10:31:16,087 - Epoch 2/25 - Validation: Loss = 1.0105, Accuracy = 0.6072\n",
      "2024-11-12 10:31:16,088 - Time for epoch 2: 61.10s\n",
      "2024-11-12 10:32:18,585 - Epoch 3/25 - Training: Loss = 0.9802, Accuracy = 0.5994\n",
      "2024-11-12 10:32:21,925 - Epoch 3/25 - Validation: Loss = 0.8099, Accuracy = 0.7045\n",
      "2024-11-12 10:32:21,926 - Time for epoch 3: 65.84s\n",
      "2024-11-12 10:33:20,954 - Epoch 4/25 - Training: Loss = 0.8503, Accuracy = 0.6610\n",
      "2024-11-12 10:33:24,258 - Epoch 4/25 - Validation: Loss = 0.7451, Accuracy = 0.7188\n",
      "2024-11-12 10:33:24,259 - Time for epoch 4: 62.33s\n",
      "2024-11-12 10:34:36,769 - Epoch 5/25 - Training: Loss = 0.7297, Accuracy = 0.7119\n",
      "2024-11-12 10:34:39,947 - Epoch 5/25 - Validation: Loss = 0.6509, Accuracy = 0.7784\n",
      "2024-11-12 10:34:39,949 - Time for epoch 5: 75.69s\n",
      "2024-11-12 10:36:01,691 - Epoch 6/25 - Training: Loss = 0.6517, Accuracy = 0.7510\n",
      "2024-11-12 10:36:05,293 - Epoch 6/25 - Validation: Loss = 0.6322, Accuracy = 0.7791\n",
      "2024-11-12 10:36:05,294 - Time for epoch 6: 85.34s\n",
      "2024-11-12 10:37:12,240 - Epoch 7/25 - Training: Loss = 0.5763, Accuracy = 0.7811\n",
      "2024-11-12 10:37:17,714 - Epoch 7/25 - Validation: Loss = 0.4929, Accuracy = 0.8224\n",
      "2024-11-12 10:37:17,715 - Time for epoch 7: 72.42s\n",
      "2024-11-12 10:38:26,191 - Epoch 8/25 - Training: Loss = 0.5180, Accuracy = 0.8014\n",
      "2024-11-12 10:38:29,416 - Epoch 8/25 - Validation: Loss = 0.4820, Accuracy = 0.8274\n",
      "2024-11-12 10:38:29,417 - Time for epoch 8: 71.70s\n",
      "2024-11-12 10:39:39,702 - Epoch 9/25 - Training: Loss = 0.4429, Accuracy = 0.8358\n",
      "2024-11-12 10:39:43,006 - Epoch 9/25 - Validation: Loss = 0.4050, Accuracy = 0.8757\n",
      "2024-11-12 10:39:43,007 - Time for epoch 9: 73.59s\n",
      "2024-11-12 10:40:42,530 - Epoch 10/25 - Training: Loss = 0.3890, Accuracy = 0.8573\n",
      "2024-11-12 10:40:45,739 - Epoch 10/25 - Validation: Loss = 0.4281, Accuracy = 0.8501\n",
      "2024-11-12 10:40:45,739 - Time for epoch 10: 62.73s\n",
      "2024-11-12 10:41:45,721 - Epoch 11/25 - Training: Loss = 0.3449, Accuracy = 0.8742\n",
      "2024-11-12 10:41:49,081 - Epoch 11/25 - Validation: Loss = 0.3370, Accuracy = 0.8928\n",
      "2024-11-12 10:41:49,083 - Time for epoch 11: 63.34s\n",
      "2024-11-12 10:42:52,341 - Epoch 12/25 - Training: Loss = 0.3203, Accuracy = 0.8824\n",
      "2024-11-12 10:42:55,865 - Epoch 12/25 - Validation: Loss = 0.3868, Accuracy = 0.8729\n",
      "2024-11-12 10:42:55,866 - Time for epoch 12: 66.78s\n",
      "2024-11-12 10:43:53,342 - Epoch 13/25 - Training: Loss = 0.2838, Accuracy = 0.8981\n",
      "2024-11-12 10:43:56,781 - Epoch 13/25 - Validation: Loss = 0.3126, Accuracy = 0.9013\n",
      "2024-11-12 10:43:56,782 - Time for epoch 13: 60.91s\n",
      "2024-11-12 10:45:05,312 - Epoch 14/25 - Training: Loss = 0.2430, Accuracy = 0.9123\n",
      "2024-11-12 10:45:09,318 - Epoch 14/25 - Validation: Loss = 0.2959, Accuracy = 0.9041\n",
      "2024-11-12 10:45:09,319 - Time for epoch 14: 72.54s\n",
      "2024-11-12 10:46:09,462 - Epoch 15/25 - Training: Loss = 0.2237, Accuracy = 0.9222\n",
      "2024-11-12 10:46:12,978 - Epoch 15/25 - Validation: Loss = 0.2963, Accuracy = 0.9006\n",
      "2024-11-12 10:46:12,979 - Time for epoch 15: 63.66s\n",
      "2024-11-12 10:47:12,661 - Epoch 16/25 - Training: Loss = 0.2001, Accuracy = 0.9281\n",
      "2024-11-12 10:47:16,954 - Epoch 16/25 - Validation: Loss = 0.2137, Accuracy = 0.9268\n",
      "2024-11-12 10:47:16,955 - Time for epoch 16: 63.97s\n",
      "2024-11-12 10:48:18,471 - Epoch 17/25 - Training: Loss = 0.1864, Accuracy = 0.9361\n",
      "2024-11-12 10:48:21,766 - Epoch 17/25 - Validation: Loss = 0.2183, Accuracy = 0.9318\n",
      "2024-11-12 10:48:21,767 - Time for epoch 17: 64.81s\n",
      "2024-11-12 10:49:23,036 - Epoch 18/25 - Training: Loss = 0.1727, Accuracy = 0.9383\n",
      "2024-11-12 10:49:26,612 - Epoch 18/25 - Validation: Loss = 0.3030, Accuracy = 0.9062\n",
      "2024-11-12 10:49:26,613 - Time for epoch 18: 64.85s\n",
      "2024-11-12 10:50:28,259 - Epoch 19/25 - Training: Loss = 0.1501, Accuracy = 0.9490\n",
      "2024-11-12 10:50:31,763 - Epoch 19/25 - Validation: Loss = 0.2280, Accuracy = 0.9197\n",
      "2024-11-12 10:50:31,764 - Time for epoch 19: 65.15s\n",
      "2024-11-12 10:51:33,807 - Epoch 20/25 - Training: Loss = 0.1193, Accuracy = 0.9586\n",
      "2024-11-12 10:51:37,471 - Epoch 20/25 - Validation: Loss = 0.1755, Accuracy = 0.9439\n",
      "2024-11-12 10:51:37,473 - Time for epoch 20: 65.71s\n",
      "2024-11-12 10:52:40,620 - Epoch 21/25 - Training: Loss = 0.1139, Accuracy = 0.9608\n",
      "2024-11-12 10:52:44,168 - Epoch 21/25 - Validation: Loss = 0.1475, Accuracy = 0.9425\n",
      "2024-11-12 10:52:44,169 - Time for epoch 21: 66.69s\n",
      "2024-11-12 10:53:45,290 - Epoch 22/25 - Training: Loss = 0.1006, Accuracy = 0.9647\n",
      "2024-11-12 10:53:48,996 - Epoch 22/25 - Validation: Loss = 0.1506, Accuracy = 0.9453\n",
      "2024-11-12 10:53:48,997 - Time for epoch 22: 64.83s\n",
      "2024-11-12 10:54:48,158 - Epoch 23/25 - Training: Loss = 0.0895, Accuracy = 0.9699\n",
      "2024-11-12 10:54:52,575 - Epoch 23/25 - Validation: Loss = 0.1255, Accuracy = 0.9581\n",
      "2024-11-12 10:54:52,576 - Time for epoch 23: 63.58s\n",
      "2024-11-12 10:55:55,081 - Epoch 24/25 - Training: Loss = 0.0888, Accuracy = 0.9688\n",
      "2024-11-12 10:55:58,532 - Epoch 24/25 - Validation: Loss = 0.2328, Accuracy = 0.9254\n",
      "2024-11-12 10:55:58,533 - Time for epoch 24: 65.96s\n",
      "2024-11-12 10:56:58,114 - Epoch 25/25 - Training: Loss = 0.0866, Accuracy = 0.9729\n",
      "2024-11-12 10:57:01,393 - Epoch 25/25 - Validation: Loss = 0.1765, Accuracy = 0.9396\n",
      "2024-11-12 10:57:01,394 - Time for epoch 25: 62.86s\n",
      "2024-11-12 10:57:01,394 - Total Training Time: 1688.84s\n",
      "2024-11-12 10:57:09,200 - Macro-Averaged F1 Score: 0.9187\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using VGG16\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.00001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 8\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.vgg16(weights=None)\n",
    "            model.classifier[6] = nn.Linear(model.classifier[6].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 03 VGG16 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_03_vgg16_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 03 VGG16 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_03_vgg16_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 03 VGG16 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_03_vgg16_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 03 VGG16 Confusion Matrix\")\n",
    "                plt.savefig('dataset_03_vgg16_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 03 VGG16 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_03_vgg16_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_03_vgg16_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">ResNet50 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 10:57:12,016 - Training dataset size: 11594\n",
      "2024-11-12 10:57:12,016 - Validation dataset size: 1408\n",
      "2024-11-12 10:57:12,017 - Test dataset size: 1529\n",
      "2024-11-12 10:57:12,018 - Training with Batch Size: 64, Learning Rate: 1e-05, Epochs: 25\n",
      "2024-11-12 10:57:56,150 - Epoch 1/25 - Training: Loss = 2.0167, Accuracy = 0.2268\n",
      "2024-11-12 10:57:58,806 - Epoch 1/25 - Validation: Loss = 1.8713, Accuracy = 0.3324\n",
      "2024-11-12 10:57:58,807 - Time for epoch 1: 46.57s\n",
      "2024-11-12 10:58:38,367 - Epoch 2/25 - Training: Loss = 1.5591, Accuracy = 0.4195\n",
      "2024-11-12 10:58:41,155 - Epoch 2/25 - Validation: Loss = 1.1964, Accuracy = 0.5483\n",
      "2024-11-12 10:58:41,156 - Time for epoch 2: 42.35s\n",
      "2024-11-12 10:59:23,058 - Epoch 3/25 - Training: Loss = 1.0518, Accuracy = 0.5762\n",
      "2024-11-12 10:59:25,570 - Epoch 3/25 - Validation: Loss = 0.8667, Accuracy = 0.6428\n",
      "2024-11-12 10:59:25,571 - Time for epoch 3: 44.41s\n",
      "2024-11-12 11:00:08,553 - Epoch 4/25 - Training: Loss = 0.8707, Accuracy = 0.6375\n",
      "2024-11-12 11:00:11,070 - Epoch 4/25 - Validation: Loss = 0.7694, Accuracy = 0.7003\n",
      "2024-11-12 11:00:11,070 - Time for epoch 4: 45.50s\n",
      "2024-11-12 11:00:57,927 - Epoch 5/25 - Training: Loss = 0.7765, Accuracy = 0.6801\n",
      "2024-11-12 11:01:00,408 - Epoch 5/25 - Validation: Loss = 0.7105, Accuracy = 0.7195\n",
      "2024-11-12 11:01:00,409 - Time for epoch 5: 49.34s\n",
      "2024-11-12 11:01:42,017 - Epoch 6/25 - Training: Loss = 0.6986, Accuracy = 0.7221\n",
      "2024-11-12 11:01:44,540 - Epoch 6/25 - Validation: Loss = 0.6368, Accuracy = 0.7429\n",
      "2024-11-12 11:01:44,541 - Time for epoch 6: 44.13s\n",
      "2024-11-12 11:02:24,369 - Epoch 7/25 - Training: Loss = 0.6330, Accuracy = 0.7527\n",
      "2024-11-12 11:02:26,810 - Epoch 7/25 - Validation: Loss = 0.6186, Accuracy = 0.7599\n",
      "2024-11-12 11:02:26,812 - Time for epoch 7: 42.27s\n",
      "2024-11-12 11:03:07,644 - Epoch 8/25 - Training: Loss = 0.5683, Accuracy = 0.7793\n",
      "2024-11-12 11:03:10,145 - Epoch 8/25 - Validation: Loss = 0.5370, Accuracy = 0.7962\n",
      "2024-11-12 11:03:10,146 - Time for epoch 8: 43.33s\n",
      "2024-11-12 11:03:51,329 - Epoch 9/25 - Training: Loss = 0.5123, Accuracy = 0.8047\n",
      "2024-11-12 11:03:53,790 - Epoch 9/25 - Validation: Loss = 0.5079, Accuracy = 0.7933\n",
      "2024-11-12 11:03:53,791 - Time for epoch 9: 43.64s\n",
      "2024-11-12 11:04:35,157 - Epoch 10/25 - Training: Loss = 0.4609, Accuracy = 0.8292\n",
      "2024-11-12 11:04:38,019 - Epoch 10/25 - Validation: Loss = 0.4559, Accuracy = 0.8303\n",
      "2024-11-12 11:04:38,020 - Time for epoch 10: 44.23s\n",
      "2024-11-12 11:05:18,531 - Epoch 11/25 - Training: Loss = 0.4185, Accuracy = 0.8466\n",
      "2024-11-12 11:05:20,927 - Epoch 11/25 - Validation: Loss = 0.4175, Accuracy = 0.8416\n",
      "2024-11-12 11:05:20,928 - Time for epoch 11: 42.91s\n",
      "2024-11-12 11:06:01,690 - Epoch 12/25 - Training: Loss = 0.3712, Accuracy = 0.8664\n",
      "2024-11-12 11:06:04,565 - Epoch 12/25 - Validation: Loss = 0.3664, Accuracy = 0.8686\n",
      "2024-11-12 11:06:04,566 - Time for epoch 12: 43.64s\n",
      "2024-11-12 11:06:44,744 - Epoch 13/25 - Training: Loss = 0.3448, Accuracy = 0.8734\n",
      "2024-11-12 11:06:47,197 - Epoch 13/25 - Validation: Loss = 0.3745, Accuracy = 0.8587\n",
      "2024-11-12 11:06:47,198 - Time for epoch 13: 42.63s\n",
      "2024-11-12 11:07:29,365 - Epoch 14/25 - Training: Loss = 0.2838, Accuracy = 0.8977\n",
      "2024-11-12 11:07:31,821 - Epoch 14/25 - Validation: Loss = 0.3162, Accuracy = 0.8771\n",
      "2024-11-12 11:07:31,821 - Time for epoch 14: 44.62s\n",
      "2024-11-12 11:08:15,429 - Epoch 15/25 - Training: Loss = 0.2570, Accuracy = 0.9093\n",
      "2024-11-12 11:08:18,722 - Epoch 15/25 - Validation: Loss = 0.2841, Accuracy = 0.8906\n",
      "2024-11-12 11:08:18,723 - Time for epoch 15: 46.90s\n",
      "2024-11-12 11:09:04,499 - Epoch 16/25 - Training: Loss = 0.2444, Accuracy = 0.9144\n",
      "2024-11-12 11:09:06,939 - Epoch 16/25 - Validation: Loss = 0.2642, Accuracy = 0.8991\n",
      "2024-11-12 11:09:06,940 - Time for epoch 16: 48.22s\n",
      "2024-11-12 11:09:45,118 - Epoch 17/25 - Training: Loss = 0.2047, Accuracy = 0.9271\n",
      "2024-11-12 11:09:47,728 - Epoch 17/25 - Validation: Loss = 0.2595, Accuracy = 0.9034\n",
      "2024-11-12 11:09:47,729 - Time for epoch 17: 40.79s\n",
      "2024-11-12 11:10:29,679 - Epoch 18/25 - Training: Loss = 0.1812, Accuracy = 0.9395\n",
      "2024-11-12 11:10:32,318 - Epoch 18/25 - Validation: Loss = 0.2914, Accuracy = 0.8956\n",
      "2024-11-12 11:10:32,319 - Time for epoch 18: 44.59s\n",
      "2024-11-12 11:11:14,513 - Epoch 19/25 - Training: Loss = 0.1742, Accuracy = 0.9420\n",
      "2024-11-12 11:11:18,109 - Epoch 19/25 - Validation: Loss = 0.2498, Accuracy = 0.9027\n",
      "2024-11-12 11:11:18,110 - Time for epoch 19: 45.79s\n",
      "2024-11-12 11:11:58,362 - Epoch 20/25 - Training: Loss = 0.1710, Accuracy = 0.9411\n",
      "2024-11-12 11:12:00,904 - Epoch 20/25 - Validation: Loss = 0.2114, Accuracy = 0.9212\n",
      "2024-11-12 11:12:00,905 - Time for epoch 20: 42.79s\n",
      "2024-11-12 11:12:42,441 - Epoch 21/25 - Training: Loss = 0.1429, Accuracy = 0.9526\n",
      "2024-11-12 11:12:45,485 - Epoch 21/25 - Validation: Loss = 0.2226, Accuracy = 0.9148\n",
      "2024-11-12 11:12:45,486 - Time for epoch 21: 44.58s\n",
      "2024-11-12 11:13:28,397 - Epoch 22/25 - Training: Loss = 0.1289, Accuracy = 0.9568\n",
      "2024-11-12 11:13:31,084 - Epoch 22/25 - Validation: Loss = 0.2099, Accuracy = 0.9183\n",
      "2024-11-12 11:13:31,085 - Time for epoch 22: 45.60s\n",
      "2024-11-12 11:14:10,715 - Epoch 23/25 - Training: Loss = 0.1262, Accuracy = 0.9568\n",
      "2024-11-12 11:14:13,246 - Epoch 23/25 - Validation: Loss = 0.2080, Accuracy = 0.9233\n",
      "2024-11-12 11:14:13,247 - Time for epoch 23: 42.16s\n",
      "2024-11-12 11:14:54,549 - Epoch 24/25 - Training: Loss = 0.1185, Accuracy = 0.9602\n",
      "2024-11-12 11:14:57,567 - Epoch 24/25 - Validation: Loss = 0.2128, Accuracy = 0.9169\n",
      "2024-11-12 11:14:57,568 - Time for epoch 24: 44.32s\n",
      "2024-11-12 11:15:42,945 - Epoch 25/25 - Training: Loss = 0.1117, Accuracy = 0.9626\n",
      "2024-11-12 11:15:45,754 - Epoch 25/25 - Validation: Loss = 0.2010, Accuracy = 0.9268\n",
      "2024-11-12 11:15:45,755 - Time for epoch 25: 48.19s\n",
      "2024-11-12 11:15:45,756 - Total Training Time: 1113.48s\n",
      "2024-11-12 11:15:49,752 - Macro-Averaged F1 Score: 0.9221\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using ResNet50\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.00001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 8\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.resnet50(weights=None)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 03 ResNet50 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_03_resnet50_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 03 ResNet50 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_03_resnet50_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 03 ResNet50 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_03_resnet50_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 03 ResNet50 Confusion Matrix\")\n",
    "                plt.savefig('dataset_03_resnet50_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 03 ResNet50 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_03_resnet50_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_03_resnet50_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">EfficientNet_B0 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 07:38:36,834 - Training dataset size: 11594\n",
      "2024-11-14 07:38:36,834 - Validation dataset size: 1408\n",
      "2024-11-14 07:38:36,835 - Test dataset size: 1529\n",
      "2024-11-14 07:38:36,836 - Training with Batch Size: 64, Learning Rate: 1e-05, Epochs: 25\n",
      "2024-11-14 07:39:33,492 - Epoch 1/25 - Training: Loss = 2.0624, Accuracy = 0.1768\n",
      "2024-11-14 07:39:37,866 - Epoch 1/25 - Validation: Loss = 2.0435, Accuracy = 0.1918\n",
      "2024-11-14 07:39:37,867 - Time for epoch 1: 59.48s\n",
      "2024-11-14 07:40:14,805 - Epoch 2/25 - Training: Loss = 2.0260, Accuracy = 0.2089\n",
      "2024-11-14 07:40:17,118 - Epoch 2/25 - Validation: Loss = 1.9970, Accuracy = 0.2230\n",
      "2024-11-14 07:40:17,119 - Time for epoch 2: 39.25s\n",
      "2024-11-14 07:40:54,715 - Epoch 3/25 - Training: Loss = 1.9069, Accuracy = 0.2757\n",
      "2024-11-14 07:40:56,954 - Epoch 3/25 - Validation: Loss = 1.7035, Accuracy = 0.3232\n",
      "2024-11-14 07:40:56,955 - Time for epoch 3: 39.84s\n",
      "2024-11-14 07:41:33,877 - Epoch 4/25 - Training: Loss = 1.6862, Accuracy = 0.3314\n",
      "2024-11-14 07:41:36,106 - Epoch 4/25 - Validation: Loss = 1.5362, Accuracy = 0.4006\n",
      "2024-11-14 07:41:36,107 - Time for epoch 4: 39.15s\n",
      "2024-11-14 07:42:13,459 - Epoch 5/25 - Training: Loss = 1.5669, Accuracy = 0.3623\n",
      "2024-11-14 07:42:21,264 - Epoch 5/25 - Validation: Loss = 1.4464, Accuracy = 0.4375\n",
      "2024-11-14 07:42:21,265 - Time for epoch 5: 45.16s\n",
      "2024-11-14 07:42:58,262 - Epoch 6/25 - Training: Loss = 1.4858, Accuracy = 0.3919\n",
      "2024-11-14 07:43:00,527 - Epoch 6/25 - Validation: Loss = 1.4000, Accuracy = 0.4723\n",
      "2024-11-14 07:43:00,528 - Time for epoch 6: 39.26s\n",
      "2024-11-14 07:43:39,392 - Epoch 7/25 - Training: Loss = 1.4034, Accuracy = 0.4313\n",
      "2024-11-14 07:43:41,726 - Epoch 7/25 - Validation: Loss = 1.3083, Accuracy = 0.4993\n",
      "2024-11-14 07:43:41,727 - Time for epoch 7: 41.20s\n",
      "2024-11-14 07:44:18,523 - Epoch 8/25 - Training: Loss = 1.3039, Accuracy = 0.4701\n",
      "2024-11-14 07:44:20,856 - Epoch 8/25 - Validation: Loss = 1.1571, Accuracy = 0.5526\n",
      "2024-11-14 07:44:20,857 - Time for epoch 8: 39.13s\n",
      "2024-11-14 07:44:57,635 - Epoch 9/25 - Training: Loss = 1.1674, Accuracy = 0.5251\n",
      "2024-11-14 07:44:59,914 - Epoch 9/25 - Validation: Loss = 0.9944, Accuracy = 0.6222\n",
      "2024-11-14 07:44:59,915 - Time for epoch 9: 39.06s\n",
      "2024-11-14 07:45:36,798 - Epoch 10/25 - Training: Loss = 1.0596, Accuracy = 0.5723\n",
      "2024-11-14 07:45:39,026 - Epoch 10/25 - Validation: Loss = 0.9016, Accuracy = 0.6605\n",
      "2024-11-14 07:45:39,027 - Time for epoch 10: 39.11s\n",
      "2024-11-14 07:46:15,613 - Epoch 11/25 - Training: Loss = 0.9737, Accuracy = 0.6033\n",
      "2024-11-14 07:46:17,835 - Epoch 11/25 - Validation: Loss = 0.8421, Accuracy = 0.6797\n",
      "2024-11-14 07:46:17,835 - Time for epoch 11: 38.81s\n",
      "2024-11-14 07:46:54,323 - Epoch 12/25 - Training: Loss = 0.9087, Accuracy = 0.6386\n",
      "2024-11-14 07:46:56,630 - Epoch 12/25 - Validation: Loss = 0.7597, Accuracy = 0.7095\n",
      "2024-11-14 07:46:56,631 - Time for epoch 12: 38.79s\n",
      "2024-11-14 07:47:33,188 - Epoch 13/25 - Training: Loss = 0.8564, Accuracy = 0.6619\n",
      "2024-11-14 07:47:35,438 - Epoch 13/25 - Validation: Loss = 0.6900, Accuracy = 0.7564\n",
      "2024-11-14 07:47:35,438 - Time for epoch 13: 38.81s\n",
      "2024-11-14 07:48:11,872 - Epoch 14/25 - Training: Loss = 0.7905, Accuracy = 0.6883\n",
      "2024-11-14 07:48:14,088 - Epoch 14/25 - Validation: Loss = 0.6326, Accuracy = 0.7663\n",
      "2024-11-14 07:48:14,089 - Time for epoch 14: 38.65s\n",
      "2024-11-14 07:48:57,138 - Epoch 15/25 - Training: Loss = 0.7494, Accuracy = 0.7104\n",
      "2024-11-14 07:48:59,355 - Epoch 15/25 - Validation: Loss = 0.5978, Accuracy = 0.7855\n",
      "2024-11-14 07:48:59,356 - Time for epoch 15: 45.27s\n",
      "2024-11-14 07:49:35,885 - Epoch 16/25 - Training: Loss = 0.7105, Accuracy = 0.7275\n",
      "2024-11-14 07:49:38,102 - Epoch 16/25 - Validation: Loss = 0.5692, Accuracy = 0.7898\n",
      "2024-11-14 07:49:38,102 - Time for epoch 16: 38.75s\n",
      "2024-11-14 07:50:15,341 - Epoch 17/25 - Training: Loss = 0.6715, Accuracy = 0.7451\n",
      "2024-11-14 07:50:17,618 - Epoch 17/25 - Validation: Loss = 0.5281, Accuracy = 0.8075\n",
      "2024-11-14 07:50:17,619 - Time for epoch 17: 39.52s\n",
      "2024-11-14 07:50:55,009 - Epoch 18/25 - Training: Loss = 0.6385, Accuracy = 0.7570\n",
      "2024-11-14 07:50:57,281 - Epoch 18/25 - Validation: Loss = 0.4956, Accuracy = 0.8189\n",
      "2024-11-14 07:50:57,282 - Time for epoch 18: 39.66s\n",
      "2024-11-14 07:51:35,468 - Epoch 19/25 - Training: Loss = 0.6029, Accuracy = 0.7698\n",
      "2024-11-14 07:51:37,997 - Epoch 19/25 - Validation: Loss = 0.4626, Accuracy = 0.8303\n",
      "2024-11-14 07:51:37,998 - Time for epoch 19: 40.72s\n",
      "2024-11-14 07:52:14,619 - Epoch 20/25 - Training: Loss = 0.5668, Accuracy = 0.7861\n",
      "2024-11-14 07:52:16,941 - Epoch 20/25 - Validation: Loss = 0.4438, Accuracy = 0.8288\n",
      "2024-11-14 07:52:16,942 - Time for epoch 20: 38.94s\n",
      "2024-11-14 07:52:54,044 - Epoch 21/25 - Training: Loss = 0.5394, Accuracy = 0.7980\n",
      "2024-11-14 07:52:56,266 - Epoch 21/25 - Validation: Loss = 0.3942, Accuracy = 0.8544\n",
      "2024-11-14 07:52:56,267 - Time for epoch 21: 39.32s\n",
      "2024-11-14 07:53:32,616 - Epoch 22/25 - Training: Loss = 0.5119, Accuracy = 0.8117\n",
      "2024-11-14 07:53:34,828 - Epoch 22/25 - Validation: Loss = 0.3773, Accuracy = 0.8544\n",
      "2024-11-14 07:53:34,829 - Time for epoch 22: 38.56s\n",
      "2024-11-14 07:54:12,520 - Epoch 23/25 - Training: Loss = 0.4887, Accuracy = 0.8196\n",
      "2024-11-14 07:54:14,721 - Epoch 23/25 - Validation: Loss = 0.3727, Accuracy = 0.8572\n",
      "2024-11-14 07:54:14,721 - Time for epoch 23: 39.89s\n",
      "2024-11-14 07:54:51,134 - Epoch 24/25 - Training: Loss = 0.4544, Accuracy = 0.8327\n",
      "2024-11-14 07:54:53,438 - Epoch 24/25 - Validation: Loss = 0.3622, Accuracy = 0.8679\n",
      "2024-11-14 07:54:53,439 - Time for epoch 24: 38.71s\n",
      "2024-11-14 07:55:31,394 - Epoch 25/25 - Training: Loss = 0.4343, Accuracy = 0.8424\n",
      "2024-11-14 07:55:33,627 - Epoch 25/25 - Validation: Loss = 0.3282, Accuracy = 0.8764\n",
      "2024-11-14 07:55:33,628 - Time for epoch 25: 40.19s\n",
      "2024-11-14 07:55:33,628 - Total Training Time: 1015.21s\n",
      "2024-11-14 07:55:38,934 - Macro-Averaged F1 Score: 0.8659\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using EfficientNet-B0\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.00001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 8\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.efficientnet_b0(weights=None)\n",
    "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 03 EfficientNet_B0 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_03_EfficientNet_B0_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 03 EfficientNet_B0 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_03_EfficientNet_B0_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 03 EfficientNet_B0 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_03_EfficientNet_B0_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 03 EfficientNet_B0 Confusion Matrix\")\n",
    "                plt.savefig('dataset_03_EfficientNet_B0_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 03 EfficientNet_B0 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_03_EfficientNet_B0_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_03_efficientnet_b0_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Inception_V3 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 07:55:40,900 - Training dataset size: 11594\n",
      "2024-11-14 07:55:40,901 - Validation dataset size: 1408\n",
      "2024-11-14 07:55:40,901 - Test dataset size: 1529\n",
      "2024-11-14 07:55:40,903 - Training with Batch Size: 64, Learning Rate: 1e-05, Epochs: 25\n",
      "2024-11-14 07:56:48,662 - Epoch 1/25 - Training: Loss = 1.9835, Accuracy = 0.2305\n",
      "2024-11-14 07:56:52,972 - Epoch 1/25 - Validation: Loss = 1.8199, Accuracy = 0.3814\n",
      "2024-11-14 07:56:52,973 - Time for epoch 1: 71.72s\n",
      "2024-11-14 07:58:00,053 - Epoch 2/25 - Training: Loss = 1.6878, Accuracy = 0.4061\n",
      "2024-11-14 07:58:04,445 - Epoch 2/25 - Validation: Loss = 1.4483, Accuracy = 0.5256\n",
      "2024-11-14 07:58:04,446 - Time for epoch 2: 71.47s\n",
      "2024-11-14 08:00:06,121 - Epoch 3/25 - Training: Loss = 1.3439, Accuracy = 0.5154\n",
      "2024-11-14 08:00:11,816 - Epoch 3/25 - Validation: Loss = 1.1438, Accuracy = 0.6101\n",
      "2024-11-14 08:00:11,818 - Time for epoch 3: 127.37s\n",
      "2024-11-14 08:02:08,682 - Epoch 4/25 - Training: Loss = 1.1130, Accuracy = 0.5731\n",
      "2024-11-14 08:02:12,959 - Epoch 4/25 - Validation: Loss = 0.9687, Accuracy = 0.6491\n",
      "2024-11-14 08:02:12,960 - Time for epoch 4: 121.14s\n",
      "2024-11-14 08:03:19,304 - Epoch 5/25 - Training: Loss = 0.9582, Accuracy = 0.6275\n",
      "2024-11-14 08:03:23,550 - Epoch 5/25 - Validation: Loss = 0.8486, Accuracy = 0.6932\n",
      "2024-11-14 08:03:23,551 - Time for epoch 5: 70.59s\n",
      "2024-11-14 08:04:29,758 - Epoch 6/25 - Training: Loss = 0.8473, Accuracy = 0.6701\n",
      "2024-11-14 08:04:40,460 - Epoch 6/25 - Validation: Loss = 0.7495, Accuracy = 0.7209\n",
      "2024-11-14 08:04:40,461 - Time for epoch 6: 76.91s\n",
      "2024-11-14 08:05:51,002 - Epoch 7/25 - Training: Loss = 0.7555, Accuracy = 0.7073\n",
      "2024-11-14 08:05:55,685 - Epoch 7/25 - Validation: Loss = 0.6865, Accuracy = 0.7472\n",
      "2024-11-14 08:05:55,686 - Time for epoch 7: 75.22s\n",
      "2024-11-14 08:07:07,688 - Epoch 8/25 - Training: Loss = 0.6833, Accuracy = 0.7394\n",
      "2024-11-14 08:07:13,044 - Epoch 8/25 - Validation: Loss = 0.5880, Accuracy = 0.7919\n",
      "2024-11-14 08:07:13,045 - Time for epoch 8: 77.36s\n",
      "2024-11-14 08:08:22,128 - Epoch 9/25 - Training: Loss = 0.6077, Accuracy = 0.7731\n",
      "2024-11-14 08:08:26,434 - Epoch 9/25 - Validation: Loss = 0.5173, Accuracy = 0.8295\n",
      "2024-11-14 08:08:26,434 - Time for epoch 9: 73.39s\n",
      "2024-11-14 08:09:42,701 - Epoch 10/25 - Training: Loss = 0.5410, Accuracy = 0.8008\n",
      "2024-11-14 08:09:47,013 - Epoch 10/25 - Validation: Loss = 0.4722, Accuracy = 0.8366\n",
      "2024-11-14 08:09:47,015 - Time for epoch 10: 80.58s\n",
      "2024-11-14 08:10:54,184 - Epoch 11/25 - Training: Loss = 0.4760, Accuracy = 0.8310\n",
      "2024-11-14 08:10:58,488 - Epoch 11/25 - Validation: Loss = 0.3946, Accuracy = 0.8679\n",
      "2024-11-14 08:10:58,489 - Time for epoch 11: 71.47s\n",
      "2024-11-14 08:12:08,474 - Epoch 12/25 - Training: Loss = 0.4186, Accuracy = 0.8576\n",
      "2024-11-14 08:12:13,195 - Epoch 12/25 - Validation: Loss = 0.3456, Accuracy = 0.8849\n",
      "2024-11-14 08:12:13,197 - Time for epoch 12: 74.71s\n",
      "2024-11-14 08:13:22,236 - Epoch 13/25 - Training: Loss = 0.3725, Accuracy = 0.8713\n",
      "2024-11-14 08:13:26,559 - Epoch 13/25 - Validation: Loss = 0.3089, Accuracy = 0.8878\n",
      "2024-11-14 08:13:26,561 - Time for epoch 13: 73.36s\n",
      "2024-11-14 08:14:48,292 - Epoch 14/25 - Training: Loss = 0.3265, Accuracy = 0.8895\n",
      "2024-11-14 08:15:01,730 - Epoch 14/25 - Validation: Loss = 0.2769, Accuracy = 0.9013\n",
      "2024-11-14 08:15:01,731 - Time for epoch 14: 95.17s\n",
      "2024-11-14 08:16:19,673 - Epoch 15/25 - Training: Loss = 0.2891, Accuracy = 0.9054\n",
      "2024-11-14 08:16:23,968 - Epoch 15/25 - Validation: Loss = 0.2471, Accuracy = 0.9105\n",
      "2024-11-14 08:16:23,968 - Time for epoch 15: 82.24s\n",
      "2024-11-14 08:17:32,079 - Epoch 16/25 - Training: Loss = 0.2654, Accuracy = 0.9122\n",
      "2024-11-14 08:17:36,282 - Epoch 16/25 - Validation: Loss = 0.2243, Accuracy = 0.9197\n",
      "2024-11-14 08:17:36,283 - Time for epoch 16: 72.31s\n",
      "2024-11-14 08:18:51,191 - Epoch 17/25 - Training: Loss = 0.2418, Accuracy = 0.9199\n",
      "2024-11-14 08:18:55,414 - Epoch 17/25 - Validation: Loss = 0.2008, Accuracy = 0.9304\n",
      "2024-11-14 08:18:55,416 - Time for epoch 17: 79.13s\n",
      "2024-11-14 08:20:39,484 - Epoch 18/25 - Training: Loss = 0.2131, Accuracy = 0.9318\n",
      "2024-11-14 08:20:56,282 - Epoch 18/25 - Validation: Loss = 0.1783, Accuracy = 0.9396\n",
      "2024-11-14 08:20:56,284 - Time for epoch 18: 120.87s\n",
      "2024-11-14 08:22:27,080 - Epoch 19/25 - Training: Loss = 0.1920, Accuracy = 0.9397\n",
      "2024-11-14 08:22:31,332 - Epoch 19/25 - Validation: Loss = 0.1908, Accuracy = 0.9304\n",
      "2024-11-14 08:22:31,333 - Time for epoch 19: 95.05s\n",
      "2024-11-14 08:23:37,640 - Epoch 20/25 - Training: Loss = 0.1767, Accuracy = 0.9439\n",
      "2024-11-14 08:23:41,847 - Epoch 20/25 - Validation: Loss = 0.1641, Accuracy = 0.9482\n",
      "2024-11-14 08:23:41,848 - Time for epoch 20: 70.51s\n",
      "2024-11-14 08:24:54,579 - Epoch 21/25 - Training: Loss = 0.1607, Accuracy = 0.9507\n",
      "2024-11-14 08:24:58,807 - Epoch 21/25 - Validation: Loss = 0.1555, Accuracy = 0.9482\n",
      "2024-11-14 08:24:58,808 - Time for epoch 21: 76.96s\n",
      "2024-11-14 08:26:04,785 - Epoch 22/25 - Training: Loss = 0.1540, Accuracy = 0.9520\n",
      "2024-11-14 08:26:09,050 - Epoch 22/25 - Validation: Loss = 0.1461, Accuracy = 0.9517\n",
      "2024-11-14 08:26:09,051 - Time for epoch 22: 70.24s\n",
      "2024-11-14 08:27:20,171 - Epoch 23/25 - Training: Loss = 0.1369, Accuracy = 0.9578\n",
      "2024-11-14 08:27:24,422 - Epoch 23/25 - Validation: Loss = 0.1436, Accuracy = 0.9503\n",
      "2024-11-14 08:27:24,423 - Time for epoch 23: 75.37s\n",
      "2024-11-14 08:28:30,538 - Epoch 24/25 - Training: Loss = 0.1382, Accuracy = 0.9566\n",
      "2024-11-14 08:28:34,755 - Epoch 24/25 - Validation: Loss = 0.1259, Accuracy = 0.9560\n",
      "2024-11-14 08:28:34,756 - Time for epoch 24: 70.33s\n",
      "2024-11-14 08:29:44,728 - Epoch 25/25 - Training: Loss = 0.1131, Accuracy = 0.9663\n",
      "2024-11-14 08:29:48,969 - Epoch 25/25 - Validation: Loss = 0.1280, Accuracy = 0.9538\n",
      "2024-11-14 08:29:48,970 - Time for epoch 25: 74.21s\n",
      "2024-11-14 08:29:48,971 - Total Training Time: 2047.67s\n",
      "2024-11-14 08:30:15,137 - Macro-Averaged F1 Score: 0.9342\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using InceptionV3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset3_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.00001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 8\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.inception_v3(weights=None, aux_logits=False, init_weights=True)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Dataset 03 Inception_V3 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_03_Inception_V3_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Dataset 03 Inception_V3 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_03_Inception_V3_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Dataset 03 Inception_V3 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_03_Inception_V3_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Dataset 03 Inception_V3 Confusion Matrix\")\n",
    "                plt.savefig('dataset_03_Inception_V3_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Dataset 03 Inception_V3 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_03_Inception_V3_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_03_inception_v3_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Combined Dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">VGG16 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 12:04:52,334 - Training dataset size: 21802\n",
      "2024-11-12 12:04:52,335 - Validation dataset size: 2673\n",
      "2024-11-12 12:04:52,335 - Test dataset size: 2827\n",
      "2024-11-12 12:04:52,337 - Training with Batch Size: 64, Learning Rate: 1e-05, Epochs: 25\n",
      "2024-11-12 12:07:19,746 - Epoch 1/25 - Training: Loss = 1.7890, Accuracy = 0.3299\n",
      "2024-11-12 12:07:29,521 - Epoch 1/25 - Validation: Loss = 1.3709, Accuracy = 0.4860\n",
      "2024-11-12 12:07:29,523 - Time for epoch 1: 156.05s\n",
      "2024-11-12 12:09:26,261 - Epoch 2/25 - Training: Loss = 1.3098, Accuracy = 0.5333\n",
      "2024-11-12 12:09:33,155 - Epoch 2/25 - Validation: Loss = 1.2753, Accuracy = 0.5305\n",
      "2024-11-12 12:09:33,156 - Time for epoch 2: 123.63s\n",
      "2024-11-12 12:11:28,858 - Epoch 3/25 - Training: Loss = 1.0973, Accuracy = 0.6188\n",
      "2024-11-12 12:11:35,860 - Epoch 3/25 - Validation: Loss = 1.1293, Accuracy = 0.5918\n",
      "2024-11-12 12:11:35,861 - Time for epoch 3: 122.70s\n",
      "2024-11-12 12:13:31,750 - Epoch 4/25 - Training: Loss = 0.9202, Accuracy = 0.6799\n",
      "2024-11-12 12:13:38,341 - Epoch 4/25 - Validation: Loss = 0.8347, Accuracy = 0.7033\n",
      "2024-11-12 12:13:38,342 - Time for epoch 4: 122.48s\n",
      "2024-11-12 12:15:40,707 - Epoch 5/25 - Training: Loss = 0.7540, Accuracy = 0.7396\n",
      "2024-11-12 12:15:47,014 - Epoch 5/25 - Validation: Loss = 0.6561, Accuracy = 0.7748\n",
      "2024-11-12 12:15:47,015 - Time for epoch 5: 128.67s\n",
      "2024-11-12 12:17:51,969 - Epoch 6/25 - Training: Loss = 0.5887, Accuracy = 0.7985\n",
      "2024-11-12 12:17:58,438 - Epoch 6/25 - Validation: Loss = 0.5975, Accuracy = 0.7909\n",
      "2024-11-12 12:17:58,440 - Time for epoch 6: 131.42s\n",
      "2024-11-12 12:19:52,846 - Epoch 7/25 - Training: Loss = 0.4729, Accuracy = 0.8368\n",
      "2024-11-12 12:19:59,151 - Epoch 7/25 - Validation: Loss = 0.4736, Accuracy = 0.8257\n",
      "2024-11-12 12:19:59,153 - Time for epoch 7: 120.71s\n",
      "2024-11-12 12:21:53,436 - Epoch 8/25 - Training: Loss = 0.3794, Accuracy = 0.8703\n",
      "2024-11-12 12:21:59,402 - Epoch 8/25 - Validation: Loss = 0.3934, Accuracy = 0.8556\n",
      "2024-11-12 12:21:59,403 - Time for epoch 8: 120.25s\n",
      "2024-11-12 12:23:54,484 - Epoch 9/25 - Training: Loss = 0.3067, Accuracy = 0.8951\n",
      "2024-11-12 12:24:00,790 - Epoch 9/25 - Validation: Loss = 0.3973, Accuracy = 0.8646\n",
      "2024-11-12 12:24:00,791 - Time for epoch 9: 121.39s\n",
      "2024-11-12 12:25:55,449 - Epoch 10/25 - Training: Loss = 0.2545, Accuracy = 0.9120\n",
      "2024-11-12 12:26:01,428 - Epoch 10/25 - Validation: Loss = 0.3152, Accuracy = 0.8885\n",
      "2024-11-12 12:26:01,429 - Time for epoch 10: 120.64s\n",
      "2024-11-12 12:27:55,919 - Epoch 11/25 - Training: Loss = 0.2070, Accuracy = 0.9283\n",
      "2024-11-12 12:28:02,708 - Epoch 11/25 - Validation: Loss = 0.3715, Accuracy = 0.8795\n",
      "2024-11-12 12:28:02,709 - Time for epoch 11: 121.28s\n",
      "2024-11-12 12:29:58,548 - Epoch 12/25 - Training: Loss = 0.1771, Accuracy = 0.9407\n",
      "2024-11-12 12:30:04,564 - Epoch 12/25 - Validation: Loss = 0.3069, Accuracy = 0.9001\n",
      "2024-11-12 12:30:04,566 - Time for epoch 12: 121.85s\n",
      "2024-11-12 12:31:58,342 - Epoch 13/25 - Training: Loss = 0.1449, Accuracy = 0.9503\n",
      "2024-11-12 12:32:04,478 - Epoch 13/25 - Validation: Loss = 0.2910, Accuracy = 0.8997\n",
      "2024-11-12 12:32:04,479 - Time for epoch 13: 119.91s\n",
      "2024-11-12 12:34:06,391 - Epoch 14/25 - Training: Loss = 0.1223, Accuracy = 0.9585\n",
      "2024-11-12 12:34:14,152 - Epoch 14/25 - Validation: Loss = 0.2659, Accuracy = 0.9091\n",
      "2024-11-12 12:34:14,154 - Time for epoch 14: 129.67s\n",
      "2024-11-12 12:36:08,006 - Epoch 15/25 - Training: Loss = 0.1059, Accuracy = 0.9640\n",
      "2024-11-12 12:36:15,923 - Epoch 15/25 - Validation: Loss = 0.2324, Accuracy = 0.9285\n",
      "2024-11-12 12:36:15,924 - Time for epoch 15: 121.77s\n",
      "2024-11-12 12:38:13,727 - Epoch 16/25 - Training: Loss = 0.0914, Accuracy = 0.9675\n",
      "2024-11-12 12:38:21,632 - Epoch 16/25 - Validation: Loss = 0.2431, Accuracy = 0.9184\n",
      "2024-11-12 12:38:21,633 - Time for epoch 16: 125.71s\n",
      "2024-11-12 12:40:20,470 - Epoch 17/25 - Training: Loss = 0.0865, Accuracy = 0.9700\n",
      "2024-11-12 12:40:26,834 - Epoch 17/25 - Validation: Loss = 0.2549, Accuracy = 0.9140\n",
      "2024-11-12 12:40:26,835 - Time for epoch 17: 125.20s\n",
      "2024-11-12 12:42:26,076 - Epoch 18/25 - Training: Loss = 0.0615, Accuracy = 0.9803\n",
      "2024-11-12 12:42:32,298 - Epoch 18/25 - Validation: Loss = 0.1959, Accuracy = 0.9405\n",
      "2024-11-12 12:42:32,300 - Time for epoch 18: 125.46s\n",
      "2024-11-12 12:44:30,950 - Epoch 19/25 - Training: Loss = 0.0603, Accuracy = 0.9793\n",
      "2024-11-12 12:44:39,337 - Epoch 19/25 - Validation: Loss = 0.2493, Accuracy = 0.9308\n",
      "2024-11-12 12:44:39,338 - Time for epoch 19: 127.04s\n",
      "2024-11-12 12:46:36,546 - Epoch 20/25 - Training: Loss = 0.0564, Accuracy = 0.9802\n",
      "2024-11-12 12:46:43,567 - Epoch 20/25 - Validation: Loss = 0.1901, Accuracy = 0.9405\n",
      "2024-11-12 12:46:43,568 - Time for epoch 20: 124.23s\n",
      "2024-11-12 12:48:43,525 - Epoch 21/25 - Training: Loss = 0.0521, Accuracy = 0.9825\n",
      "2024-11-12 12:48:50,495 - Epoch 21/25 - Validation: Loss = 0.2396, Accuracy = 0.9353\n",
      "2024-11-12 12:48:50,496 - Time for epoch 21: 126.93s\n",
      "2024-11-12 12:50:48,056 - Epoch 22/25 - Training: Loss = 0.0472, Accuracy = 0.9857\n",
      "2024-11-12 12:50:54,154 - Epoch 22/25 - Validation: Loss = 0.2312, Accuracy = 0.9263\n",
      "2024-11-12 12:50:54,155 - Time for epoch 22: 123.66s\n",
      "2024-11-12 12:52:50,714 - Epoch 23/25 - Training: Loss = 0.0396, Accuracy = 0.9869\n",
      "2024-11-12 12:52:57,327 - Epoch 23/25 - Validation: Loss = 0.1677, Accuracy = 0.9484\n",
      "2024-11-12 12:52:57,328 - Time for epoch 23: 123.17s\n",
      "2024-11-12 12:54:55,433 - Epoch 24/25 - Training: Loss = 0.0420, Accuracy = 0.9864\n",
      "2024-11-12 12:55:01,833 - Epoch 24/25 - Validation: Loss = 0.1741, Accuracy = 0.9469\n",
      "2024-11-12 12:55:01,834 - Time for epoch 24: 124.50s\n",
      "2024-11-12 12:57:05,085 - Epoch 25/25 - Training: Loss = 0.0371, Accuracy = 0.9879\n",
      "2024-11-12 12:57:12,280 - Epoch 25/25 - Validation: Loss = 0.2136, Accuracy = 0.9342\n",
      "2024-11-12 12:57:12,281 - Time for epoch 25: 130.45s\n",
      "2024-11-12 12:57:12,282 - Total Training Time: 3138.77s\n",
      "2024-11-12 12:57:25,531 - Macro-Averaged F1 Score: 0.9315\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using VGG16\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.00001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.vgg16(weights=None)\n",
    "            model.classifier[6] = nn.Linear(model.classifier[6].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Combined Dataset VGG16 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_vgg16_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Combined Dataset VGG16 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_vgg16_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Combined Dataset VGG16 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_04_vgg16_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Combined Dataset VGG16 Confusion Matrix\")\n",
    "                plt.savefig('dataset_04_vgg16_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Combined Dataset VGG16 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_04_vgg16_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_04_vgg16_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">ResNet50 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 12:57:28,455 - Training dataset size: 21802\n",
      "2024-11-12 12:57:28,456 - Validation dataset size: 2673\n",
      "2024-11-12 12:57:28,456 - Test dataset size: 2827\n",
      "2024-11-12 12:57:28,458 - Training with Batch Size: 128, Learning Rate: 5e-05, Epochs: 25\n",
      "2024-11-12 12:58:41,925 - Epoch 1/25 - Training: Loss = 1.7063, Accuracy = 0.3695\n",
      "2024-11-12 12:58:46,768 - Epoch 1/25 - Validation: Loss = 1.6191, Accuracy = 0.4074\n",
      "2024-11-12 12:58:46,769 - Time for epoch 1: 78.09s\n",
      "2024-11-12 13:00:01,946 - Epoch 2/25 - Training: Loss = 1.2438, Accuracy = 0.5499\n",
      "2024-11-12 13:00:06,804 - Epoch 2/25 - Validation: Loss = 1.1753, Accuracy = 0.5769\n",
      "2024-11-12 13:00:06,806 - Time for epoch 2: 80.03s\n",
      "2024-11-12 13:01:20,467 - Epoch 3/25 - Training: Loss = 1.0146, Accuracy = 0.6399\n",
      "2024-11-12 13:01:25,215 - Epoch 3/25 - Validation: Loss = 0.9116, Accuracy = 0.6831\n",
      "2024-11-12 13:01:25,217 - Time for epoch 3: 78.41s\n",
      "2024-11-12 13:02:39,667 - Epoch 4/25 - Training: Loss = 0.8084, Accuracy = 0.7192\n",
      "2024-11-12 13:02:44,721 - Epoch 4/25 - Validation: Loss = 0.7757, Accuracy = 0.7273\n",
      "2024-11-12 13:02:44,722 - Time for epoch 4: 79.50s\n",
      "2024-11-12 13:04:00,113 - Epoch 5/25 - Training: Loss = 0.6308, Accuracy = 0.7780\n",
      "2024-11-12 13:04:04,869 - Epoch 5/25 - Validation: Loss = 0.6530, Accuracy = 0.7647\n",
      "2024-11-12 13:04:04,870 - Time for epoch 5: 80.15s\n",
      "2024-11-12 13:05:16,413 - Epoch 6/25 - Training: Loss = 0.4891, Accuracy = 0.8292\n",
      "2024-11-12 13:05:21,041 - Epoch 6/25 - Validation: Loss = 0.6046, Accuracy = 0.7770\n",
      "2024-11-12 13:05:21,041 - Time for epoch 6: 76.17s\n",
      "2024-11-12 13:06:38,499 - Epoch 7/25 - Training: Loss = 0.3814, Accuracy = 0.8679\n",
      "2024-11-12 13:06:44,035 - Epoch 7/25 - Validation: Loss = 0.4370, Accuracy = 0.8451\n",
      "2024-11-12 13:06:44,037 - Time for epoch 7: 82.99s\n",
      "2024-11-12 13:07:57,123 - Epoch 8/25 - Training: Loss = 0.2917, Accuracy = 0.8980\n",
      "2024-11-12 13:08:01,624 - Epoch 8/25 - Validation: Loss = 0.4530, Accuracy = 0.8511\n",
      "2024-11-12 13:08:01,624 - Time for epoch 8: 77.59s\n",
      "2024-11-12 13:09:23,563 - Epoch 9/25 - Training: Loss = 0.2312, Accuracy = 0.9217\n",
      "2024-11-12 13:09:28,253 - Epoch 9/25 - Validation: Loss = 0.4177, Accuracy = 0.8601\n",
      "2024-11-12 13:09:28,254 - Time for epoch 9: 86.63s\n",
      "2024-11-12 13:10:47,478 - Epoch 10/25 - Training: Loss = 0.1635, Accuracy = 0.9469\n",
      "2024-11-12 13:10:52,095 - Epoch 10/25 - Validation: Loss = 0.4233, Accuracy = 0.8605\n",
      "2024-11-12 13:10:52,096 - Time for epoch 10: 83.84s\n",
      "2024-11-12 13:12:05,418 - Epoch 11/25 - Training: Loss = 0.1207, Accuracy = 0.9606\n",
      "2024-11-12 13:12:12,439 - Epoch 11/25 - Validation: Loss = 0.3068, Accuracy = 0.9005\n",
      "2024-11-12 13:12:12,440 - Time for epoch 11: 80.34s\n",
      "2024-11-12 13:13:24,779 - Epoch 12/25 - Training: Loss = 0.0953, Accuracy = 0.9689\n",
      "2024-11-12 13:13:29,485 - Epoch 12/25 - Validation: Loss = 0.2662, Accuracy = 0.9080\n",
      "2024-11-12 13:13:29,486 - Time for epoch 12: 77.04s\n",
      "2024-11-12 13:14:46,682 - Epoch 13/25 - Training: Loss = 0.0777, Accuracy = 0.9749\n",
      "2024-11-12 13:14:52,402 - Epoch 13/25 - Validation: Loss = 0.2837, Accuracy = 0.9016\n",
      "2024-11-12 13:14:52,403 - Time for epoch 13: 82.92s\n",
      "2024-11-12 13:16:07,376 - Epoch 14/25 - Training: Loss = 0.0649, Accuracy = 0.9793\n",
      "2024-11-12 13:16:13,306 - Epoch 14/25 - Validation: Loss = 0.2621, Accuracy = 0.9241\n",
      "2024-11-12 13:16:13,307 - Time for epoch 14: 80.90s\n",
      "2024-11-12 13:17:27,812 - Epoch 15/25 - Training: Loss = 0.0484, Accuracy = 0.9847\n",
      "2024-11-12 13:17:32,749 - Epoch 15/25 - Validation: Loss = 0.2990, Accuracy = 0.9196\n",
      "2024-11-12 13:17:32,750 - Time for epoch 15: 79.44s\n",
      "2024-11-12 13:18:48,826 - Epoch 16/25 - Training: Loss = 0.0479, Accuracy = 0.9854\n",
      "2024-11-12 13:18:53,440 - Epoch 16/25 - Validation: Loss = 0.2346, Accuracy = 0.9252\n",
      "2024-11-12 13:18:53,441 - Time for epoch 16: 80.69s\n",
      "2024-11-12 13:20:06,502 - Epoch 17/25 - Training: Loss = 0.0433, Accuracy = 0.9867\n",
      "2024-11-12 13:20:11,388 - Epoch 17/25 - Validation: Loss = 0.2582, Accuracy = 0.9244\n",
      "2024-11-12 13:20:11,389 - Time for epoch 17: 77.95s\n",
      "2024-11-12 13:21:23,239 - Epoch 18/25 - Training: Loss = 0.0248, Accuracy = 0.9929\n",
      "2024-11-12 13:21:29,239 - Epoch 18/25 - Validation: Loss = 0.2925, Accuracy = 0.9192\n",
      "2024-11-12 13:21:29,241 - Time for epoch 18: 77.85s\n",
      "2024-11-12 13:22:42,820 - Epoch 19/25 - Training: Loss = 0.0257, Accuracy = 0.9925\n",
      "2024-11-12 13:22:47,420 - Epoch 19/25 - Validation: Loss = 0.2452, Accuracy = 0.9327\n",
      "2024-11-12 13:22:47,421 - Time for epoch 19: 78.18s\n",
      "2024-11-12 13:24:01,633 - Epoch 20/25 - Training: Loss = 0.0267, Accuracy = 0.9925\n",
      "2024-11-12 13:24:07,089 - Epoch 20/25 - Validation: Loss = 0.2910, Accuracy = 0.9188\n",
      "2024-11-12 13:24:07,090 - Time for epoch 20: 79.67s\n",
      "2024-11-12 13:25:18,143 - Epoch 21/25 - Training: Loss = 0.0347, Accuracy = 0.9890\n",
      "2024-11-12 13:25:22,682 - Epoch 21/25 - Validation: Loss = 0.2526, Accuracy = 0.9241\n",
      "2024-11-12 13:25:22,683 - Time for epoch 21: 75.59s\n",
      "2024-11-12 13:26:36,592 - Epoch 22/25 - Training: Loss = 0.0200, Accuracy = 0.9942\n",
      "2024-11-12 13:26:41,627 - Epoch 22/25 - Validation: Loss = 0.2249, Accuracy = 0.9420\n",
      "2024-11-12 13:26:41,628 - Time for epoch 22: 78.94s\n",
      "2024-11-12 13:27:51,266 - Epoch 23/25 - Training: Loss = 0.0220, Accuracy = 0.9936\n",
      "2024-11-12 13:27:55,873 - Epoch 23/25 - Validation: Loss = 0.2108, Accuracy = 0.9413\n",
      "2024-11-12 13:27:55,874 - Time for epoch 23: 74.24s\n",
      "2024-11-12 13:29:15,212 - Epoch 24/25 - Training: Loss = 0.0188, Accuracy = 0.9949\n",
      "2024-11-12 13:29:20,946 - Epoch 24/25 - Validation: Loss = 0.2372, Accuracy = 0.9371\n",
      "2024-11-12 13:29:20,948 - Time for epoch 24: 85.07s\n",
      "2024-11-12 13:30:35,131 - Epoch 25/25 - Training: Loss = 0.0266, Accuracy = 0.9924\n",
      "2024-11-12 13:30:40,286 - Epoch 25/25 - Validation: Loss = 0.2533, Accuracy = 0.9293\n",
      "2024-11-12 13:30:40,288 - Time for epoch 25: 79.34s\n",
      "2024-11-12 13:30:40,288 - Total Training Time: 1991.57s\n",
      "2024-11-12 13:30:48,750 - Macro-Averaged F1 Score: 0.9176\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using ResNet50\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.00005]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.resnet50(weights=None)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Combined Dataset ResNet50 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_resnet50_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Combined Dataset ResNet50 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_resnet50_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Combined Dataset ResNet50 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_04_resnet50_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Combined Dataset ResNet50 Confusion Matrix\")\n",
    "                plt.savefig('dataset_04_resnet50_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Combined Dataset ResNet50 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_04_resnet50_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_04_resnet50_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">EfficientNet_B0 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 13:30:51,127 - Training dataset size: 21802\n",
      "2024-11-12 13:30:51,128 - Validation dataset size: 2673\n",
      "2024-11-12 13:30:51,128 - Test dataset size: 2827\n",
      "2024-11-12 13:30:51,129 - Training with Batch Size: 128, Learning Rate: 5e-05, Epochs: 25\n",
      "2024-11-12 13:32:11,076 - Epoch 1/25 - Training: Loss = 2.1180, Accuracy = 0.2041\n",
      "2024-11-12 13:32:17,783 - Epoch 1/25 - Validation: Loss = 1.8279, Accuracy = 0.3008\n",
      "2024-11-12 13:32:17,785 - Time for epoch 1: 86.58s\n",
      "2024-11-12 13:33:28,487 - Epoch 2/25 - Training: Loss = 1.7019, Accuracy = 0.3564\n",
      "2024-11-12 13:33:32,934 - Epoch 2/25 - Validation: Loss = 1.5024, Accuracy = 0.4572\n",
      "2024-11-12 13:33:32,936 - Time for epoch 2: 75.15s\n",
      "2024-11-12 13:34:43,602 - Epoch 3/25 - Training: Loss = 1.3890, Accuracy = 0.4968\n",
      "2024-11-12 13:34:48,684 - Epoch 3/25 - Validation: Loss = 1.1935, Accuracy = 0.5630\n",
      "2024-11-12 13:34:48,686 - Time for epoch 3: 75.75s\n",
      "2024-11-12 13:35:58,734 - Epoch 4/25 - Training: Loss = 1.1630, Accuracy = 0.5865\n",
      "2024-11-12 13:36:03,992 - Epoch 4/25 - Validation: Loss = 1.0148, Accuracy = 0.6364\n",
      "2024-11-12 13:36:03,994 - Time for epoch 4: 75.31s\n",
      "2024-11-12 13:37:17,638 - Epoch 5/25 - Training: Loss = 1.0038, Accuracy = 0.6454\n",
      "2024-11-12 13:37:21,716 - Epoch 5/25 - Validation: Loss = 0.8564, Accuracy = 0.7030\n",
      "2024-11-12 13:37:21,717 - Time for epoch 5: 77.72s\n",
      "2024-11-12 13:38:34,221 - Epoch 6/25 - Training: Loss = 0.8645, Accuracy = 0.6951\n",
      "2024-11-12 13:38:39,248 - Epoch 6/25 - Validation: Loss = 0.8217, Accuracy = 0.7018\n",
      "2024-11-12 13:38:39,249 - Time for epoch 6: 77.53s\n",
      "2024-11-12 13:39:50,533 - Epoch 7/25 - Training: Loss = 0.7447, Accuracy = 0.7374\n",
      "2024-11-12 13:39:55,230 - Epoch 7/25 - Validation: Loss = 0.7186, Accuracy = 0.7422\n",
      "2024-11-12 13:39:55,231 - Time for epoch 7: 75.98s\n",
      "2024-11-12 13:41:06,793 - Epoch 8/25 - Training: Loss = 0.6331, Accuracy = 0.7810\n",
      "2024-11-12 13:41:11,152 - Epoch 8/25 - Validation: Loss = 0.6358, Accuracy = 0.7673\n",
      "2024-11-12 13:41:11,153 - Time for epoch 8: 75.92s\n",
      "2024-11-12 13:42:22,560 - Epoch 9/25 - Training: Loss = 0.5397, Accuracy = 0.8134\n",
      "2024-11-12 13:42:26,771 - Epoch 9/25 - Validation: Loss = 0.5474, Accuracy = 0.7987\n",
      "2024-11-12 13:42:26,773 - Time for epoch 9: 75.62s\n",
      "2024-11-12 13:43:40,437 - Epoch 10/25 - Training: Loss = 0.4643, Accuracy = 0.8382\n",
      "2024-11-12 13:43:46,339 - Epoch 10/25 - Validation: Loss = 0.4755, Accuracy = 0.8290\n",
      "2024-11-12 13:43:46,340 - Time for epoch 10: 79.57s\n",
      "2024-11-12 13:44:56,613 - Epoch 11/25 - Training: Loss = 0.3921, Accuracy = 0.8635\n",
      "2024-11-12 13:45:00,719 - Epoch 11/25 - Validation: Loss = 0.4116, Accuracy = 0.8537\n",
      "2024-11-12 13:45:00,720 - Time for epoch 11: 74.38s\n",
      "2024-11-12 13:46:14,442 - Epoch 12/25 - Training: Loss = 0.3561, Accuracy = 0.8782\n",
      "2024-11-12 13:46:18,604 - Epoch 12/25 - Validation: Loss = 0.3828, Accuracy = 0.8691\n",
      "2024-11-12 13:46:18,605 - Time for epoch 12: 77.88s\n",
      "2024-11-12 13:47:28,397 - Epoch 13/25 - Training: Loss = 0.3057, Accuracy = 0.8957\n",
      "2024-11-12 13:47:32,414 - Epoch 13/25 - Validation: Loss = 0.3220, Accuracy = 0.8833\n",
      "2024-11-12 13:47:32,414 - Time for epoch 13: 73.81s\n",
      "2024-11-12 13:48:44,160 - Epoch 14/25 - Training: Loss = 0.2693, Accuracy = 0.9073\n",
      "2024-11-12 13:48:48,706 - Epoch 14/25 - Validation: Loss = 0.3229, Accuracy = 0.8822\n",
      "2024-11-12 13:48:48,707 - Time for epoch 14: 76.29s\n",
      "2024-11-12 13:49:59,891 - Epoch 15/25 - Training: Loss = 0.2292, Accuracy = 0.9212\n",
      "2024-11-12 13:50:03,960 - Epoch 15/25 - Validation: Loss = 0.3278, Accuracy = 0.8881\n",
      "2024-11-12 13:50:03,961 - Time for epoch 15: 75.25s\n",
      "2024-11-12 13:51:18,042 - Epoch 16/25 - Training: Loss = 0.2098, Accuracy = 0.9301\n",
      "2024-11-12 13:51:22,267 - Epoch 16/25 - Validation: Loss = 0.2649, Accuracy = 0.9027\n",
      "2024-11-12 13:51:22,268 - Time for epoch 16: 78.31s\n",
      "2024-11-12 13:52:33,683 - Epoch 17/25 - Training: Loss = 0.1897, Accuracy = 0.9365\n",
      "2024-11-12 13:52:38,440 - Epoch 17/25 - Validation: Loss = 0.2758, Accuracy = 0.9042\n",
      "2024-11-12 13:52:38,441 - Time for epoch 17: 76.17s\n",
      "2024-11-12 13:53:49,332 - Epoch 18/25 - Training: Loss = 0.1690, Accuracy = 0.9420\n",
      "2024-11-12 13:53:54,368 - Epoch 18/25 - Validation: Loss = 0.2650, Accuracy = 0.9083\n",
      "2024-11-12 13:53:54,369 - Time for epoch 18: 75.93s\n",
      "2024-11-12 13:55:02,523 - Epoch 19/25 - Training: Loss = 0.1518, Accuracy = 0.9506\n",
      "2024-11-12 13:55:07,068 - Epoch 19/25 - Validation: Loss = 0.2307, Accuracy = 0.9211\n",
      "2024-11-12 13:55:07,070 - Time for epoch 19: 72.70s\n",
      "2024-11-12 13:56:15,463 - Epoch 20/25 - Training: Loss = 0.1401, Accuracy = 0.9530\n",
      "2024-11-12 13:56:20,436 - Epoch 20/25 - Validation: Loss = 0.2394, Accuracy = 0.9207\n",
      "2024-11-12 13:56:20,438 - Time for epoch 20: 73.37s\n",
      "2024-11-12 13:57:28,578 - Epoch 21/25 - Training: Loss = 0.1251, Accuracy = 0.9603\n",
      "2024-11-12 13:57:33,752 - Epoch 21/25 - Validation: Loss = 0.2163, Accuracy = 0.9327\n",
      "2024-11-12 13:57:33,753 - Time for epoch 21: 73.31s\n",
      "2024-11-12 13:58:44,185 - Epoch 22/25 - Training: Loss = 0.1133, Accuracy = 0.9622\n",
      "2024-11-12 13:58:48,303 - Epoch 22/25 - Validation: Loss = 0.2279, Accuracy = 0.9342\n",
      "2024-11-12 13:58:48,304 - Time for epoch 22: 74.55s\n",
      "2024-11-12 14:00:01,898 - Epoch 23/25 - Training: Loss = 0.1035, Accuracy = 0.9656\n",
      "2024-11-12 14:00:06,065 - Epoch 23/25 - Validation: Loss = 0.2362, Accuracy = 0.9274\n",
      "2024-11-12 14:00:06,066 - Time for epoch 23: 77.76s\n",
      "2024-11-12 14:01:14,625 - Epoch 24/25 - Training: Loss = 0.1007, Accuracy = 0.9667\n",
      "2024-11-12 14:01:19,327 - Epoch 24/25 - Validation: Loss = 0.1879, Accuracy = 0.9394\n",
      "2024-11-12 14:01:19,328 - Time for epoch 24: 73.26s\n",
      "2024-11-12 14:02:31,525 - Epoch 25/25 - Training: Loss = 0.0898, Accuracy = 0.9715\n",
      "2024-11-12 14:02:36,932 - Epoch 25/25 - Validation: Loss = 0.2341, Accuracy = 0.9312\n",
      "2024-11-12 14:02:36,933 - Time for epoch 25: 77.60s\n",
      "2024-11-12 14:02:36,933 - Total Training Time: 1905.69s\n",
      "2024-11-12 14:02:43,469 - Macro-Averaged F1 Score: 0.9417\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using EfficientNet-B0\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [128]\n",
    "learning_rates = [0.00005]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.efficientnet_b0(weights=None)\n",
    "            model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Combined Dataset EfficientNet_B0 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_EfficientNet_B0_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Combined Dataset EfficientNet_B0 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_EfficientNet_B0_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Combined Dataset EfficientNet_B0 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_04_EfficientNet_B0_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Combined Dataset EfficientNet_B0 Confusion Matrix\")\n",
    "                plt.savefig('dataset_04_EfficientNet_B0_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Combined Dataset EfficientNet_B0 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_04_EfficientNet_B0_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_04_efficientnet_b0_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Inception_V3 Model training</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 14:02:45,680 - Training dataset size: 21802\n",
      "2024-11-12 14:02:45,681 - Validation dataset size: 2673\n",
      "2024-11-12 14:02:45,681 - Test dataset size: 2827\n",
      "2024-11-12 14:02:45,683 - Training with Batch Size: 64, Learning Rate: 0.0001, Epochs: 25\n",
      "2024-11-12 14:04:59,007 - Epoch 1/25 - Training: Loss = 1.4714, Accuracy = 0.4627\n",
      "2024-11-12 14:05:06,757 - Epoch 1/25 - Validation: Loss = 1.1926, Accuracy = 0.5593\n",
      "2024-11-12 14:05:06,758 - Time for epoch 1: 140.80s\n",
      "2024-11-12 14:07:12,590 - Epoch 2/25 - Training: Loss = 0.9756, Accuracy = 0.6521\n",
      "2024-11-12 14:07:20,260 - Epoch 2/25 - Validation: Loss = 0.8669, Accuracy = 0.6891\n",
      "2024-11-12 14:07:20,262 - Time for epoch 2: 133.50s\n",
      "2024-11-12 14:09:29,371 - Epoch 3/25 - Training: Loss = 0.7513, Accuracy = 0.7381\n",
      "2024-11-12 14:09:37,760 - Epoch 3/25 - Validation: Loss = 0.7306, Accuracy = 0.7235\n",
      "2024-11-12 14:09:37,761 - Time for epoch 3: 137.50s\n",
      "2024-11-12 14:11:46,736 - Epoch 4/25 - Training: Loss = 0.5979, Accuracy = 0.7914\n",
      "2024-11-12 14:11:54,399 - Epoch 4/25 - Validation: Loss = 0.6524, Accuracy = 0.7587\n",
      "2024-11-12 14:11:54,400 - Time for epoch 4: 136.64s\n",
      "2024-11-12 14:14:05,035 - Epoch 5/25 - Training: Loss = 0.4707, Accuracy = 0.8362\n",
      "2024-11-12 14:14:13,805 - Epoch 5/25 - Validation: Loss = 0.4882, Accuracy = 0.8328\n",
      "2024-11-12 14:14:13,807 - Time for epoch 5: 139.40s\n",
      "2024-11-12 14:16:21,728 - Epoch 6/25 - Training: Loss = 0.3816, Accuracy = 0.8672\n",
      "2024-11-12 14:16:30,220 - Epoch 6/25 - Validation: Loss = 0.4431, Accuracy = 0.8403\n",
      "2024-11-12 14:16:30,221 - Time for epoch 6: 136.41s\n",
      "2024-11-12 14:18:44,037 - Epoch 7/25 - Training: Loss = 0.3185, Accuracy = 0.8895\n",
      "2024-11-12 14:18:52,497 - Epoch 7/25 - Validation: Loss = 0.4499, Accuracy = 0.8485\n",
      "2024-11-12 14:18:52,499 - Time for epoch 7: 142.28s\n",
      "2024-11-12 14:21:00,006 - Epoch 8/25 - Training: Loss = 0.2484, Accuracy = 0.9136\n",
      "2024-11-12 14:21:07,953 - Epoch 8/25 - Validation: Loss = 0.4242, Accuracy = 0.8474\n",
      "2024-11-12 14:21:07,955 - Time for epoch 8: 135.45s\n",
      "2024-11-12 14:23:18,256 - Epoch 9/25 - Training: Loss = 0.2030, Accuracy = 0.9313\n",
      "2024-11-12 14:23:26,868 - Epoch 9/25 - Validation: Loss = 0.3236, Accuracy = 0.8893\n",
      "2024-11-12 14:23:26,869 - Time for epoch 9: 138.91s\n",
      "2024-11-12 14:25:45,967 - Epoch 10/25 - Training: Loss = 0.1696, Accuracy = 0.9436\n",
      "2024-11-12 14:25:54,833 - Epoch 10/25 - Validation: Loss = 0.3107, Accuracy = 0.9005\n",
      "2024-11-12 14:25:54,834 - Time for epoch 10: 147.96s\n",
      "2024-11-12 14:28:03,396 - Epoch 11/25 - Training: Loss = 0.1376, Accuracy = 0.9525\n",
      "2024-11-12 14:28:11,662 - Epoch 11/25 - Validation: Loss = 0.3549, Accuracy = 0.8889\n",
      "2024-11-12 14:28:11,664 - Time for epoch 11: 136.83s\n",
      "2024-11-12 14:30:22,825 - Epoch 12/25 - Training: Loss = 0.1160, Accuracy = 0.9600\n",
      "2024-11-12 14:30:31,062 - Epoch 12/25 - Validation: Loss = 0.3208, Accuracy = 0.9024\n",
      "2024-11-12 14:30:31,063 - Time for epoch 12: 139.40s\n",
      "2024-11-12 14:32:39,949 - Epoch 13/25 - Training: Loss = 0.1012, Accuracy = 0.9657\n",
      "2024-11-12 14:32:52,215 - Epoch 13/25 - Validation: Loss = 0.2572, Accuracy = 0.9192\n",
      "2024-11-12 14:32:52,217 - Time for epoch 13: 141.15s\n",
      "2024-11-12 14:35:02,853 - Epoch 14/25 - Training: Loss = 0.0836, Accuracy = 0.9715\n",
      "2024-11-12 14:35:10,958 - Epoch 14/25 - Validation: Loss = 0.2538, Accuracy = 0.9252\n",
      "2024-11-12 14:35:10,959 - Time for epoch 14: 138.74s\n",
      "2024-11-12 14:37:21,173 - Epoch 15/25 - Training: Loss = 0.0753, Accuracy = 0.9754\n",
      "2024-11-12 14:37:29,470 - Epoch 15/25 - Validation: Loss = 0.2413, Accuracy = 0.9214\n",
      "2024-11-12 14:37:29,471 - Time for epoch 15: 138.51s\n",
      "2024-11-12 14:39:40,940 - Epoch 16/25 - Training: Loss = 0.0681, Accuracy = 0.9773\n",
      "2024-11-12 14:39:49,326 - Epoch 16/25 - Validation: Loss = 0.2571, Accuracy = 0.9147\n",
      "2024-11-12 14:39:49,327 - Time for epoch 16: 139.85s\n",
      "2024-11-12 14:41:58,551 - Epoch 17/25 - Training: Loss = 0.0506, Accuracy = 0.9828\n",
      "2024-11-12 14:42:06,572 - Epoch 17/25 - Validation: Loss = 0.2086, Accuracy = 0.9405\n",
      "2024-11-12 14:42:06,573 - Time for epoch 17: 137.24s\n",
      "2024-11-12 14:44:16,878 - Epoch 18/25 - Training: Loss = 0.0551, Accuracy = 0.9820\n",
      "2024-11-12 14:44:25,881 - Epoch 18/25 - Validation: Loss = 0.2697, Accuracy = 0.9196\n",
      "2024-11-12 14:44:25,882 - Time for epoch 18: 139.31s\n",
      "2024-11-12 14:46:32,040 - Epoch 19/25 - Training: Loss = 0.0357, Accuracy = 0.9883\n",
      "2024-11-12 14:46:39,846 - Epoch 19/25 - Validation: Loss = 0.2090, Accuracy = 0.9330\n",
      "2024-11-12 14:46:39,848 - Time for epoch 19: 133.96s\n",
      "2024-11-12 14:48:46,907 - Epoch 20/25 - Training: Loss = 0.0449, Accuracy = 0.9852\n",
      "2024-11-12 14:48:56,047 - Epoch 20/25 - Validation: Loss = 0.1762, Accuracy = 0.9454\n",
      "2024-11-12 14:48:56,049 - Time for epoch 20: 136.20s\n",
      "2024-11-12 14:51:03,946 - Epoch 21/25 - Training: Loss = 0.0409, Accuracy = 0.9866\n",
      "2024-11-12 14:51:11,952 - Epoch 21/25 - Validation: Loss = 0.1756, Accuracy = 0.9461\n",
      "2024-11-12 14:51:11,953 - Time for epoch 21: 135.90s\n",
      "2024-11-12 14:53:22,888 - Epoch 22/25 - Training: Loss = 0.0306, Accuracy = 0.9899\n",
      "2024-11-12 14:53:31,783 - Epoch 22/25 - Validation: Loss = 0.1503, Accuracy = 0.9577\n",
      "2024-11-12 14:53:31,785 - Time for epoch 22: 139.83s\n",
      "2024-11-12 14:55:37,080 - Epoch 23/25 - Training: Loss = 0.0275, Accuracy = 0.9916\n",
      "2024-11-12 14:55:46,194 - Epoch 23/25 - Validation: Loss = 0.2304, Accuracy = 0.9379\n",
      "2024-11-12 14:55:46,195 - Time for epoch 23: 134.41s\n",
      "2024-11-12 14:57:55,259 - Epoch 24/25 - Training: Loss = 0.0340, Accuracy = 0.9891\n",
      "2024-11-12 14:58:02,958 - Epoch 24/25 - Validation: Loss = 0.2173, Accuracy = 0.9375\n",
      "2024-11-12 14:58:02,959 - Time for epoch 24: 136.76s\n",
      "2024-11-12 15:00:10,003 - Epoch 25/25 - Training: Loss = 0.0321, Accuracy = 0.9893\n",
      "2024-11-12 15:00:17,823 - Epoch 25/25 - Validation: Loss = 0.1738, Accuracy = 0.9566\n",
      "2024-11-12 15:00:17,825 - Time for epoch 25: 134.86s\n",
      "2024-11-12 15:00:17,825 - Total Training Time: 3451.82s\n",
      "2024-11-12 15:00:27,194 - Macro-Averaged F1 Score: 0.9519\n"
     ]
    }
   ],
   "source": [
    "# Written by Ovi, 2024-11-11\n",
    "# Image classification pipeline using InceptionV3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_fscore_support, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ensure reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths\n",
    "train_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/train'\n",
    "val_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/val'\n",
    "test_dir = '/scratch/movi/dm_project/data/split_80/dataset4_aug/test'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_sizes = [64]\n",
    "learning_rates = [0.0001]\n",
    "epoch_counts = [25]\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=data_transforms['test'])\n",
    "\n",
    "logger.info(f\"Training dataset size: {len(train_dataset)}\")\n",
    "logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "logger.info(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_acc_history, val_acc_history = [], []\n",
    "    train_loss_history, val_loss_history = [], []\n",
    "    total_training_time = 0\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_acc_history.append(train_acc.cpu())\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Training: Loss = {train_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels.data)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(val_loss)\n",
    "        val_acc_history.append(val_acc.cpu())\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_training_time += epoch_time\n",
    "\n",
    "        logger.info(f\"Epoch {epoch + 1}/{epochs} - Validation: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "        logger.info(f\"Time for epoch {epoch + 1}: {epoch_time:.2f}s\")\n",
    "\n",
    "    logger.info(f\"Total Training Time: {total_training_time:.2f}s\")\n",
    "\n",
    "    return train_acc_history, val_acc_history, train_loss_history, val_loss_history\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for lr in learning_rates:\n",
    "        for epochs in epoch_counts:\n",
    "            logger.info(f\"Training with Batch Size: {batch_size}, Learning Rate: {lr}, Epochs: {epochs}\")\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            model = models.inception_v3(weights=None, aux_logits=False, init_weights=True)\n",
    "            model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "            model = model.to(DEVICE)\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            train_acc_history, val_acc_history, train_loss_history, val_loss_history = train_and_validate(\n",
    "                model, train_loader, val_loader, criterion, optimizer, epochs\n",
    "            )\n",
    "\n",
    "            epochs_range = range(1, epochs + 1)\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_acc_history, label='Training Accuracy')\n",
    "            plt.plot(epochs_range, val_acc_history, label='Validation Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.title(f'Combined Dataset Inception_V3 Accuracy (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_Inception_V3_accuracy_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_range, train_loss_history, label='Training Loss')\n",
    "            plt.plot(epochs_range, val_loss_history, label='Validation Loss')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title(f'Combined Dataset Inception_V3 Loss (Batch Size {batch_size}, LR {lr}, Epochs {epochs})')\n",
    "            plt.legend()\n",
    "            plt.savefig(f'dataset_04_Inception_V3_loss_batch_{batch_size}_lr_{lr}_epochs_{epochs}.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "            plt.close()\n",
    "\n",
    "            def test_and_evaluate(model, test_loader, class_names):\n",
    "                model.eval()\n",
    "                all_labels = []\n",
    "                all_preds = []\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in test_loader:\n",
    "                        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        all_labels.extend(labels.cpu().numpy())\n",
    "                        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "                macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "                logger.info(f\"Macro-Averaged F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "                metrics_df = np.array([precision, recall, f1]).T\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(metrics_df, annot=True, cmap=\"viridis\", xticklabels=[\"Precision\", \"Recall\", \"F1\"], yticklabels=class_names)\n",
    "                plt.title(\"Combined Dataset Inception_V3 Classification Report\")\n",
    "                plt.xlabel(\"Metric\")\n",
    "                plt.ylabel(\"Class\")\n",
    "                plt.savefig('dataset_04_Inception_V3_classification_report.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                cm = confusion_matrix(all_labels, all_preds)\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                plt.xlabel(\"Predicted Label\")\n",
    "                plt.ylabel(\"True Label\")\n",
    "                plt.title(\"Combined Dataset Inception_V3 Confusion Matrix\")\n",
    "                plt.savefig('dataset_04_Inception_V3_confusion_matrix.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "                all_labels_binarized = label_binarize(all_labels, classes=np.arange(NUM_CLASSES))\n",
    "                all_preds_binarized = np.eye(NUM_CLASSES)[np.array(all_preds)]\n",
    "\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'cyan'])\n",
    "                for i, color in zip(range(NUM_CLASSES), colors):\n",
    "                    fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], all_preds_binarized[:, i])\n",
    "                    roc_auc = auc(fpr, tpr)\n",
    "                    plt.plot(fpr, tpr, color=color, lw=2, label=f'Class {class_names[i]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Combined Dataset Inception_V3 ROC Curves for All Classes')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.savefig('dataset_04_Inception_V3_ROC_All_Classes.png', dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "                plt.close()\n",
    "\n",
    "            test_and_evaluate(model, test_loader, class_names=test_dataset.classes)\n",
    "\n",
    "            torch.save(model.state_dict(), 'dataset_04_inception_v3_model_trained.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
